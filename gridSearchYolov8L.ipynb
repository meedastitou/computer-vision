{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meedastitou/computer-vision/blob/main/gridSearchYolov8L.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiwOhDHHWW9J",
        "outputId": "1a96b0ca-e275-4d37-f1d0-96d3481fe622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed May 21 14:57:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAxCMyd9T8yc",
        "outputId": "28fe924d-0518-4c7b-ebe8-3a386777d7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.142-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.142-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.142 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXK7Fqb2TxWv",
        "outputId": "2ab4d54b-f0fb-4671-93b0-3f960745a852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from torch import torch\n",
        "import gc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMKz5tqsUWr6",
        "outputId": "08ce5cef-d0f8-4dbd-9909-6c849e097c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAsH4Q8YUAwf"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CFG:\n",
        "    DEBUG = False\n",
        "    SEED = 42\n",
        "    DATASET_PATH = '/content/drive/MyDrive/dataset'\n",
        "    NAME = 'detection-PPEv7'\n",
        "    CLASSES = ['Gloves', 'Glasses', 'Shoes', 'Helmet', 'Vest', 'Person']\n",
        "    NUM_CLASSES_TO_TRAIN = len(CLASSES)\n",
        "    NUM_CORES = 2\n",
        "\n",
        "    # Base training parameters\n",
        "    EPOCHS = 3 if DEBUG else 20  # Reduced for grid search\n",
        "    BATCH_SIZE = 16\n",
        "    OPTIMIZER = 'AdamW'  # SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto\n",
        "    LR = 1e-3\n",
        "    WEIGHT_DECAY = 5e-4\n",
        "    DROPOUT = 0.0\n",
        "    PATIENCE = 20\n",
        "    PROFILE = False\n",
        "    LABEL_SMOOTHING = 0.0\n",
        "\n",
        "    # Model\n",
        "    YOLO_MODEL = \"yolov8l.pt\"\n",
        "\n",
        "    # Output\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/PPE-detection/runs\"\n",
        "    ARTIFACTS = '/content/drive/MyDrive/PPE-detection/artifacts'\n",
        "    GRIDSEARCH_DIR = '/content/drive/MyDrive/PPE-detection/gridsearch/yolov8l'\n",
        "\n",
        "    # GridSearch parameters\n",
        "    PARAM_GRID = {\n",
        "        'lr': [1e-4, 5e-4, 1e-3, 3e-3],\n",
        "        'optimizer': ['SGD', 'AdamW', 'Adam', 'RMSProp'],\n",
        "        'batch_size': [32, 16, 8]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ukBm6DeUDmQ"
      },
      "outputs": [],
      "source": [
        "def ensure_dir(dir_path):\n",
        "    \"\"\"Create directory if it doesn't exist.\"\"\"\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "        print(f\"Created directory: {dir_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFsnHUzRooQU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def run_gridsearch():\n",
        "    \"\"\"Run grid search for YOLO training.\"\"\"\n",
        "    # Ensure directories exist\n",
        "    ensure_dir(CFG.OUTPUT_DIR)\n",
        "    ensure_dir(CFG.ARTIFACTS)\n",
        "    ensure_dir(CFG.GRIDSEARCH_DIR)\n",
        "\n",
        "    # Create parameter combinations\n",
        "    param_keys = list(CFG.PARAM_GRID.keys())\n",
        "    param_values = list(CFG.PARAM_GRID.values())\n",
        "    param_combinations = list(product(*param_values))\n",
        "\n",
        "    # Create results dataframe\n",
        "    results = []\n",
        "\n",
        "    # Generate a timestamp for this grid search run\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    results_file = os.path.join(CFG.GRIDSEARCH_DIR, f\"gridsearch_results_{timestamp}.csv\")\n",
        "\n",
        "    print(f\"Starting grid search with {len(param_combinations)} combinations\")\n",
        "\n",
        "    # Run training for each parameter combination\n",
        "    for i, combination in enumerate(param_combinations):\n",
        "        params = dict(zip(param_keys, combination))\n",
        "\n",
        "        # Create a unique run name\n",
        "        run_name = f\"{CFG.NAME}_gs_{i+1}_{'_'.join([f'{k}_{v}' for k, v in params.items()])}\"\n",
        "        run_name = run_name.replace('.', '')  # Remove dots from name for filesystem compatibility\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Running combination {i+1}/{len(param_combinations)}\")\n",
        "        print(f\"Parameters: {params}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        # Load base model\n",
        "        model = YOLO(CFG.YOLO_MODEL)\n",
        "\n",
        "        # Set up training parameters\n",
        "        train_args = {\n",
        "            'data': os.path.join(CFG.DATASET_PATH, 'data.yaml'),\n",
        "            'epochs': CFG.EPOCHS,\n",
        "            'imgsz': 640,\n",
        "            'batch': params['batch_size'],\n",
        "            'device': 0,\n",
        "            'workers': CFG.NUM_CORES,\n",
        "            'project': CFG.OUTPUT_DIR,\n",
        "            'name': run_name,\n",
        "            'seed': CFG.SEED,\n",
        "            'optimizer': params['optimizer'],\n",
        "            'lr0': params['lr'],  # Initial learning rate\n",
        "            'weight_decay': CFG.WEIGHT_DECAY,\n",
        "            'val': True,\n",
        "            'amp': True,\n",
        "            'exist_ok': True,\n",
        "            'resume': False,\n",
        "            'verbose': False,\n",
        "        }\n",
        "\n",
        "        # Start timer\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train model\n",
        "        results_obj = model.train(**train_args)\n",
        "\n",
        "        # End timer\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Get metrics\n",
        "        metrics = {\n",
        "            'map50': float(results_obj.results_dict.get('metrics/mAP50(B)', 0)),\n",
        "            'map50_95': float(results_obj.results_dict.get('metrics/mAP50-95(B)', 0)),\n",
        "            'precision': float(results_obj.results_dict.get('metrics/precision(B)', 0)),\n",
        "            'recall': float(results_obj.results_dict.get('metrics/recall(B)', 0)),\n",
        "            'train_time': training_time\n",
        "        }\n",
        "\n",
        "        # Add results to list\n",
        "        result_dict = {**params, **metrics}\n",
        "        results.append(result_dict)\n",
        "\n",
        "        # Save intermediate results\n",
        "        pd.DataFrame(results).to_csv(results_file, index=False)\n",
        "        print(f\"Saved intermediate results to {results_file}\")\n",
        "\n",
        "        # Print current best model based on mAP50-95\n",
        "        if results:\n",
        "            df = pd.DataFrame(results)\n",
        "            best_idx = df['map50_95'].idxmax()\n",
        "            best_params = df.loc[best_idx].to_dict()\n",
        "            print(\"\\nCurrent best model:\")\n",
        "            print(f\"Parameters: {json.dumps({k: best_params[k] for k in param_keys}, indent=2)}\")\n",
        "            print(f\"mAP50-95: {best_params['map50_95']:.4f}\")\n",
        "            print(f\"mAP50: {best_params['map50']:4f}\")\n",
        "            print(f\"Precision: {best_params['precision']:.4f}\")\n",
        "            print(f\"Recall: {best_params['recall']:.4f}\")\n",
        "            print(f\"Training time: {best_params['train_time']:.2f} seconds\")\n",
        "        del model\n",
        "        del results_obj\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Convert results to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save final results\n",
        "    results_df.to_csv(results_file, index=False)\n",
        "\n",
        "    # Find best parameters\n",
        "    best_idx = results_df['map50_95'].idxmax()\n",
        "    best_params = results_df.loc[best_idx].to_dict()\n",
        "\n",
        "    # Create summary file\n",
        "    summary_file = os.path.join(CFG.GRIDSEARCH_DIR, f\"gridsearch_summary_{timestamp}.txt\")\n",
        "\n",
        "    with open(summary_file, 'w') as f:\n",
        "        f.write(f\"Grid Search Summary for {CFG.NAME}\\n\")\n",
        "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
        "        f.write(f\"Total combinations: {len(param_combinations)}\\n\\n\")\n",
        "\n",
        "        f.write(\"Parameter grid:\\n\")\n",
        "        for param, values in CFG.PARAM_GRID.items():\n",
        "            f.write(f\"  {param}: {values}\\n\")\n",
        "\n",
        "        f.write(\"\\nBest parameters:\\n\")\n",
        "        for param in param_keys:\n",
        "            f.write(f\"  {param}: {best_params[param]}\\n\")\n",
        "\n",
        "        f.write(\"\\nBest metrics:\\n\")\n",
        "        f.write(f\"  mAP50-95: {best_params['map50_95']:.4f}\\n\")\n",
        "        f.write(f\"  mAP50: {best_params['map50']:.4f}\\n\")\n",
        "        f.write(f\"  Precision: {best_params['precision']:.4f}\\n\")\n",
        "        f.write(f\"  Recall: {best_params['recall']:.4f}\\n\")\n",
        "        f.write(f\"  Training time: {best_params['train_time']:.2f} seconds\\n\")\n",
        "\n",
        "    print(f\"\\nGrid search completed. Results saved to {results_file}\")\n",
        "    print(f\"Summary saved to {summary_file}\")\n",
        "\n",
        "    return best_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77RIeqpZUHjS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def visualize_results(results_file):\n",
        "    \"\"\"Visualize grid search results.\"\"\"\n",
        "    # Load results\n",
        "    results_df = pd.DataFrame(pd.read_csv(results_file))\n",
        "\n",
        "    # Create plots directory\n",
        "    plots_dir = os.path.join(CFG.GRIDSEARCH_DIR, 'plots')\n",
        "    ensure_dir(plots_dir)\n",
        "\n",
        "    # Import visualization libraries\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    # Set plot style\n",
        "    plt.style.use('ggplot')\n",
        "\n",
        "    # 1. Learning rate vs mAP50-95 for different optimizers\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for optimizer in results_df['optimizer'].unique():\n",
        "        data = results_df[results_df['optimizer'] == optimizer]\n",
        "        plt.plot(data['lr'], data['map50'], marker='o', label=optimizer)\n",
        "\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Learning Rate')\n",
        "    plt.ylabel('mAP50')\n",
        "    plt.title('Learning Rate vs mAP50 for Different Optimizers')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plot_path = os.path.join(plots_dir, 'lr_vs_map.png')\n",
        "    plt.savefig(plot_path)\n",
        "\n",
        "    # 2. Heatmap of mAP50-95 for different optimizers and learning rates\n",
        "    for batch_size in results_df['batch_size'].unique():\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        pivot_df = results_df[results_df['batch_size'] == batch_size].pivot_table(\n",
        "            index='optimizer', columns='lr', values='map50'\n",
        "        )\n",
        "        sns.heatmap(pivot_df, annot=True, cmap='viridis', fmt='.4f')\n",
        "        plt.title(f'mAP50 for Different Optimizers and Learning Rates (Batch Size: {batch_size})')\n",
        "        plt.tight_layout()\n",
        "        plot_path = os.path.join(plots_dir, f'heatmap_batch_{batch_size}.png')\n",
        "        plt.savefig(plot_path)\n",
        "\n",
        "    # 3. Training time comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x='optimizer', y='train_time', hue='batch_size', data=results_df)\n",
        "    plt.title('Training Time Comparison')\n",
        "    plt.xlabel('Optimizer')\n",
        "    plt.ylabel('Training Time (seconds)')\n",
        "    plt.grid(True, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plot_path = os.path.join(plots_dir, 'training_time.png')\n",
        "    plt.savefig(plot_path)\n",
        "\n",
        "    print(f\"Visualizations saved to {plots_dir}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5ab2amqULdW"
      },
      "outputs": [],
      "source": [
        "def train_with_best_params(best_params):\n",
        "    \"\"\"Train a final model with the best parameters found from grid search.\"\"\"\n",
        "    print(\"\\nTraining final model with best parameters...\")\n",
        "\n",
        "    # Create a unique run name for the final model\n",
        "    run_name = f\"{CFG.NAME}_final_{'_'.join([f'{k}_{v}' for k, v in best_params.items() if k in CFG.PARAM_GRID.keys()])}\"\n",
        "    run_name = run_name.replace('.', '')  # Remove dots for filesystem compatibility\n",
        "\n",
        "    # Load base model\n",
        "    model = YOLO(CFG.YOLO_MODEL)\n",
        "\n",
        "    # Set up training parameters with the full number of epochs\n",
        "    train_args = {\n",
        "        'data': os.path.join(CFG.DATASET_PATH, 'data.yaml'),\n",
        "        'epochs': 100,\n",
        "        'imgsz': 640,\n",
        "        'batch': best_params['batch_size'],\n",
        "        'device': 0,\n",
        "        'workers': CFG.NUM_CORES,\n",
        "        'project': CFG.OUTPUT_DIR,\n",
        "        'name': run_name,\n",
        "        'seed': CFG.SEED,\n",
        "        'optimizer': best_params['optimizer'],\n",
        "        'lr0': best_params['lr'],  # Initial learning rate\n",
        "        'weight_decay': CFG.WEIGHT_DECAY,\n",
        "        'val': True,\n",
        "        'amp': True,\n",
        "        'exist_ok': False,\n",
        "        'resume': False,\n",
        "        'verbose': False,\n",
        "        'patience': CFG.PATIENCE,  # Early stopping patience\n",
        "    }\n",
        "\n",
        "    # Train model\n",
        "    results = model.train(**train_args)\n",
        "\n",
        "    print(f\"\\nFinal model training completed.\")\n",
        "    print(f\"Model saved to {os.path.join(CFG.OUTPUT_DIR, run_name)}\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhzCR-fOUN9U",
        "outputId": "26680d22-a0b2-4648-daad-6dfaf7b64a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting grid search with 48 combinations\n",
            "\n",
            "================================================================================\n",
            "Running combination 1/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.7M/83.7M [00:00<00:00, 344MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 94.6MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 225MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 0.1Â±0.0 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.0 ms, read: 0.0Â±0.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20        18G      1.491      3.528      1.624         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [30:13<00:00, 22.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.294      0.195      0.222       0.17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.4G      1.411       2.41       1.58         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.328      0.227      0.262      0.179\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.6G      1.264      1.889       1.47         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.626      0.405      0.459      0.273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.6G      1.121      1.559      1.369         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.661       0.53      0.561      0.304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.6G      1.074      1.378      1.324         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.753      0.594      0.648      0.339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.6G      1.036      1.278      1.289         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.784      0.628      0.698      0.373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.6G      1.025      1.217       1.27         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.824      0.652      0.727      0.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.5G     0.9961      1.142      1.248        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.789      0.676       0.74      0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.6G     0.9863      1.124      1.239        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.846      0.672      0.751      0.421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.6G     0.9888      1.079      1.237         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.811       0.71      0.757      0.432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.5G       1.03      1.102      1.255         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.885      0.674       0.77      0.428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.5G      1.013       1.07      1.237         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.86      0.699      0.779      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.4G      1.007      1.051       1.24         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.905       0.68      0.783       0.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.3G      1.004      1.028      1.232         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.897      0.684      0.785      0.452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.3G     0.9883      1.007      1.225         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.903      0.676      0.786      0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.4G     0.9913     0.9877      1.221         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.682      0.792      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.5G     0.9865     0.9758      1.221         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.915      0.685      0.794      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.4G     0.9802     0.9686      1.209         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.907      0.696      0.795      0.463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.3G     0.9818      0.968      1.218         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.86      0.727      0.798      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.5G     0.9784     0.9666      1.213         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908       0.69      0.797      0.463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.956 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.86      0.728      0.798      0.465\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_1_lr_00001_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"SGD\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.4648\n",
            "mAP50: 0.797723\n",
            "Precision: 0.8601\n",
            "Recall: 0.7280\n",
            "Training time: 3497.20 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 2/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.2 ms, read: 17.0Â±11.4 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.7 ms, read: 11.4Â±11.3 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.11G      1.489      3.331      1.635         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.278      0.197       0.22      0.166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.5G       1.37      2.333      1.558        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.289      0.231      0.273      0.183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.6G       1.24      1.849      1.455         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.609      0.462      0.494      0.286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.6G      1.125      1.556      1.372         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.673      0.551      0.571      0.305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.6G      1.075      1.395      1.322         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.774      0.594      0.646      0.339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.6G      1.045      1.293      1.295         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.784      0.628       0.69      0.373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.6G      1.016      1.223      1.275         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887      0.585      0.711      0.383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.6G      1.017      1.184      1.264         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.849      0.635      0.731      0.394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.6G      1.004      1.146      1.254         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.865      0.628      0.742      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.6G     0.9696      1.098      1.236         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887       0.62      0.751      0.417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.6G      1.031      1.116      1.259         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.896      0.645      0.764      0.432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.6G      1.016      1.095      1.252         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.858      0.678      0.768      0.435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.6G      1.003      1.065      1.245         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.673      0.778      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.6G      1.004      1.041      1.234         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.902      0.677      0.782       0.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.6G      0.996       1.02      1.234         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.926      0.653      0.785      0.457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.6G      1.002      1.014      1.232         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.91      0.672      0.783      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.6G      0.991     0.9998      1.232         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.954      0.657      0.787      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.6G     0.9815     0.9904      1.219         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.921      0.673      0.786      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.6G     0.9873     0.9939      1.226         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.947       0.66      0.786      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.6G     0.9824     0.9805      1.223         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.942      0.668      0.785      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.469 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.947      0.661      0.785      0.466\n",
            "Speed: 0.3ms preprocess, 10.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_2_lr_00001_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"SGD\",\n",
            "  \"batch_size\": 16\n",
            "}\n",
            "mAP50-95: 0.4656\n",
            "mAP50: 0.785366\n",
            "Precision: 0.9474\n",
            "Recall: 0.6610\n",
            "Training time: 1701.76 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 3/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'SGD', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 34.2Â±16.5 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 35.6Â±22.5 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      4.98G      1.475      3.219      1.631         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.283      0.191      0.221      0.165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.52G      1.351      2.312      1.549         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.365      0.268      0.289      0.188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.84G      1.237      1.849      1.453         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.636      0.473      0.487      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.84G      1.127      1.586      1.376        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.671      0.555      0.595      0.319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.84G      1.077       1.44      1.331         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.763      0.576      0.642      0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      5.84G       1.05      1.342      1.306         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.822      0.591      0.689      0.359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      5.84G      1.021      1.274      1.286         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.817      0.611      0.714      0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      5.84G      1.014      1.222      1.269         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.795      0.663      0.726      0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      5.85G      1.002      1.182      1.262         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.83      0.649      0.742      0.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      5.85G     0.9883      1.164      1.249        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.845       0.67      0.751       0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      5.85G      1.039      1.177      1.266         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.893      0.663       0.76      0.427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      5.85G      1.022      1.129      1.258         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.885      0.704       0.77      0.436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      5.85G       1.01      1.106      1.255         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.867      0.696      0.774      0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      5.85G      1.012      1.089      1.247         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.928      0.666      0.776      0.447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      5.85G      1.003      1.064      1.249         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.924      0.678      0.778      0.457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      5.85G      1.002      1.057      1.239         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889      0.701       0.78      0.451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      5.85G      1.004      1.037      1.243         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286        0.9      0.686      0.784      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      5.85G     0.9984      1.025      1.234         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.933      0.668      0.783      0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      5.85G     0.9948      1.034       1.24         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.897      0.692      0.782      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      5.85G     0.9868      1.029      1.231         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.933      0.672      0.784      0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.457 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.927      0.672      0.783      0.457\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_3_lr_00001_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"SGD\",\n",
            "  \"batch_size\": 16\n",
            "}\n",
            "mAP50-95: 0.4656\n",
            "mAP50: 0.785366\n",
            "Precision: 0.9474\n",
            "Recall: 0.6610\n",
            "Training time: 1701.76 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 4/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'AdamW', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 36.4Â±23.2 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 29.3Â±21.9 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.4G      1.144      1.665      1.342         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.689      0.514      0.595      0.272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.033      1.074      1.257         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.793      0.676      0.723      0.369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G     0.9945     0.9665      1.224         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.825      0.675      0.771      0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G     0.9615     0.9181      1.211         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.82      0.729      0.795      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G     0.9267     0.8502      1.195         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.828      0.731      0.793      0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G     0.8868     0.7982      1.165         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.865      0.793      0.851      0.505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G     0.8732      0.764      1.158         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.862      0.787      0.857      0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G     0.8359     0.7014      1.131        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.859      0.773      0.838      0.511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G     0.8177     0.6826      1.112        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.835      0.798      0.845      0.544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G     0.7966     0.6458        1.1         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.896      0.802      0.871      0.558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G     0.8122     0.5819      1.106         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.881      0.836      0.889      0.597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G     0.7812     0.5459      1.085         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.897      0.792      0.887      0.586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.5G     0.7546     0.5254      1.071         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.911       0.84      0.909       0.62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G     0.7238     0.4948      1.054         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.928      0.822      0.904      0.638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G     0.6998     0.4685      1.039         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.897      0.851       0.91      0.624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G     0.6745     0.4422      1.024         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.933      0.854      0.911      0.651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G     0.6567     0.4228      1.015         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.917      0.839       0.92      0.662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G     0.6369     0.4049     0.9978         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.934      0.824      0.908      0.647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G       0.62     0.3906     0.9986         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.912      0.852       0.92      0.667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G     0.5963     0.3767     0.9822         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.961      0.824      0.922      0.672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.478 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.961      0.824      0.922      0.673\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_4_lr_00001_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 5/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'AdamW', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 38.5Â±22.2 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.4 ms, read: 17.4Â±17.6 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.26G      1.141      1.544      1.353         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.786      0.548      0.631      0.318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.049      1.119      1.273        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.866      0.659      0.749      0.428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.019      1.029      1.247         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.844      0.682      0.797      0.445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G     0.9843     0.9558      1.228         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.877      0.699      0.797      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.8G     0.9463      0.887        1.2         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.821      0.704       0.81      0.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.8G     0.9263     0.8429      1.184         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.861      0.769      0.818      0.493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.8G     0.8833     0.7844      1.157         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.903      0.767      0.838       0.54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.8G     0.8729      0.746      1.141         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889       0.78      0.842      0.505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.8G     0.8521      0.719      1.134         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.902      0.783      0.859      0.548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.8G     0.8079     0.6795      1.116         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.818      0.831      0.873      0.561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.8G     0.8266     0.6007      1.117         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.909      0.794       0.88       0.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.8G     0.7987     0.5687      1.102         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.936      0.774      0.879      0.588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.8G      0.769     0.5371      1.086         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.928      0.793        0.9      0.615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.8G     0.7414     0.5028      1.066         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.93       0.81      0.912      0.619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.8G     0.7082     0.4787      1.053         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.929      0.831      0.918      0.609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.8G     0.6989     0.4625      1.035         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.923      0.852      0.913      0.639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.8G     0.6734     0.4426      1.024         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.911       0.85      0.915      0.618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.8G      0.659     0.4205      1.009         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.934      0.858       0.92      0.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.8G     0.6398     0.4138      1.005         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.904      0.889      0.925      0.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.8G      0.619     0.3951     0.9934         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.917      0.881      0.927      0.669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.470 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.917       0.88      0.927      0.669\n",
            "Speed: 0.2ms preprocess, 9.5ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_5_lr_00001_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 6/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'AdamW', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 20.3Â±15.1 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 32.5Â±18.6 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.09G      1.149      1.518      1.372         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.848       0.62      0.672      0.357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.88G       1.06      1.209      1.295         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.735      0.643      0.691      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.93G      1.031      1.083      1.261         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.727      0.665      0.696      0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.94G     0.9959     0.9991      1.246        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.767      0.746      0.754      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.94G     0.9597     0.9367      1.226         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.812      0.737      0.796      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      5.94G     0.9348     0.8963      1.211         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.84      0.734      0.803      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      5.94G     0.9071     0.8356      1.188         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.817      0.738      0.802      0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      5.97G     0.8835      0.783      1.165         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.873      0.787      0.849      0.532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.32G     0.8733     0.7562      1.154         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.834      0.767      0.838      0.532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.32G     0.8317     0.7231      1.134        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.875      0.752      0.843      0.559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.32G     0.8435      0.632      1.128         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.767      0.843      0.563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.32G     0.8168     0.6054      1.115         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.877      0.775      0.851      0.579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.32G     0.7838     0.5715      1.104         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.888        0.8      0.867      0.584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.32G      0.762     0.5438      1.082         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.883      0.781       0.87        0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.32G     0.7312     0.5116      1.066         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.874      0.831      0.883      0.618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.32G     0.7197     0.4934      1.054         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887      0.831      0.895      0.611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.32G     0.6987     0.4703      1.042         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.925      0.824      0.906      0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.32G     0.6743     0.4471      1.027         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.935      0.824      0.909      0.629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.34G     0.6618     0.4414       1.03         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.91      0.848      0.901      0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.34G     0.6414     0.4217      1.012         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.942      0.825      0.905      0.639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.458 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.942      0.825      0.905       0.64\n",
            "Speed: 0.3ms preprocess, 9.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_6_lr_00001_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 7/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.7 ms, read: 26.6Â±16.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.5 ms, read: 15.3Â±12.1 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.5G      1.149      1.662      1.345         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.722      0.471       0.53       0.22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.038      1.095      1.274         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.81      0.662      0.747      0.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      0.996     0.9864      1.238         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.726      0.682      0.731       0.43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G      0.962     0.9266      1.211         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.854      0.647       0.74      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G     0.9274     0.8478      1.191         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.84      0.736      0.833      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G     0.8916     0.8008      1.176         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889      0.701      0.794      0.487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G     0.8759     0.7678      1.162         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.868      0.766      0.827       0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G     0.8352     0.7047      1.131        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.926      0.725       0.84      0.539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G     0.8153     0.6755      1.112        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.886       0.75      0.838       0.54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G     0.7993     0.6424      1.105         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.95      0.721      0.846      0.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G     0.8007     0.5811      1.102         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.857      0.816      0.875      0.597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G     0.7812     0.5447      1.088         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.851      0.849      0.889      0.616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.6G     0.7542     0.5236      1.069         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.867      0.814      0.879      0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G     0.7245     0.4936      1.057         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.922      0.814      0.884       0.62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G     0.7016     0.4656      1.043         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.868      0.858      0.902      0.624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G     0.6729     0.4413      1.019         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.828      0.897      0.668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G      0.655     0.4215      1.016         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.926      0.846       0.91      0.657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G     0.6381     0.4055     0.9973         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.944      0.841       0.91      0.638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G     0.6174     0.3924     0.9927         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.883      0.882      0.919      0.651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G     0.5984     0.3793     0.9794         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.927      0.843      0.921      0.672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.478 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.925      0.845      0.921      0.672\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_7_lr_00001_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 8/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.3 ms, read: 15.7Â±9.6 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 31.0Â±17.3 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.26G      1.141       1.55      1.353         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.721      0.559      0.611      0.265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.051      1.122      1.271        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.86      0.642      0.723      0.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.002      1.022      1.239         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.818      0.676      0.765      0.425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G     0.9717     0.9508      1.219         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.922      0.717        0.8      0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.8G     0.9423     0.8824      1.204         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.862      0.725      0.786      0.504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.8G     0.9218     0.8378       1.18         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.906      0.722      0.818      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.8G     0.8846     0.7859       1.16         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.883      0.707      0.816       0.55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.8G     0.8705      0.742      1.143         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.88      0.775      0.861      0.539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.8G     0.8531     0.7158      1.136         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.842       0.79      0.854      0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.8G     0.8086     0.6847       1.12         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.927      0.801      0.878      0.559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.8G     0.8242     0.6069      1.117         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.85      0.805      0.875      0.574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.8G     0.7929      0.578      1.093         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.897      0.803      0.884      0.582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.8G     0.7662     0.5348      1.079         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.934      0.796      0.893      0.618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.8G     0.7464     0.5063      1.057         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.938      0.817        0.9      0.622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.8G     0.7095     0.4776      1.044         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.861      0.883      0.902      0.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.8G     0.6923      0.459      1.032         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.866      0.913      0.648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.8G     0.6712     0.4428      1.029         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.913      0.873      0.915      0.653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.8G     0.6551     0.4216      1.008         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.937      0.865      0.919      0.649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.8G     0.6377     0.4104      1.004         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.951      0.853      0.913      0.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.8G      0.617     0.3936     0.9892         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.933       0.87      0.913      0.661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.472 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.933      0.871      0.913       0.66\n",
            "Speed: 0.2ms preprocess, 10.6ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_8_lr_00001_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 9/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'Adam', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 39.2Â±19.2 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.4 ms, read: 12.6Â±11.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.18G      1.139      1.523      1.356         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.767      0.563       0.63      0.332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.97G      1.063      1.207      1.293         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:13<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.836      0.654      0.749      0.373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      6.02G      1.034      1.091      1.264         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.77      0.686      0.722      0.366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      6.02G     0.9948      1.002       1.24        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908      0.684      0.777      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.02G     0.9713     0.9555      1.223         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.823      0.752      0.797      0.475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.02G      0.935     0.8975      1.199         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.831      0.735      0.785       0.46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.06G     0.9091     0.8264      1.176         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.853      0.733      0.828      0.466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.06G     0.8835     0.7887      1.154         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.87      0.785      0.857      0.548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.08G     0.8608     0.7575      1.148         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.84      0.775      0.851      0.542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.08G     0.8396     0.7237      1.134        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.778      0.859      0.535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.08G     0.8494     0.6387      1.136         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.888      0.777      0.868      0.558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.08G     0.8238     0.6063      1.123         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.92      0.776       0.86      0.574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.08G     0.7845     0.5708      1.105         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.916      0.785      0.863       0.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.08G     0.7649      0.543      1.083         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.903      0.806      0.887      0.595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.08G      0.737     0.5106      1.068         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.853      0.836      0.877      0.586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.08G      0.718     0.4882      1.049         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.92      0.783      0.883      0.605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.43G     0.7004     0.4672       1.04         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.932      0.834      0.906      0.615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.43G     0.6791     0.4468      1.024         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889       0.85      0.907      0.633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.43G     0.6647     0.4395      1.029         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.837      0.893      0.619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.43G     0.6408     0.4192      1.011         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.953      0.812      0.901      0.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.455 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.89      0.849      0.907      0.633\n",
            "Speed: 0.2ms preprocess, 8.3ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_9_lr_00001_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 10/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'RMSProp', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 38.6Â±20.4 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.8 ms, read: 20.2Â±23.6 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      2.133      3.869      2.336         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00296     0.0863    0.00278    0.00054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.6G      1.728      2.617      1.912         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.004     0.0808    0.00237   0.000453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G       1.63      2.419      1.812         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00334      0.107     0.0023   0.000469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G      1.577      2.308      1.745         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0242      0.122     0.0246    0.00815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      1.522      2.226      1.709         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0585     0.0648     0.0105    0.00365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.446      2.128      1.659         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.123     0.0993     0.0412     0.0185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G      1.422       2.06      1.623         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.404      0.116     0.0928     0.0375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.382      1.977      1.598        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.129      0.411      0.179     0.0744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G      1.373      1.955       1.58        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.155     0.0988     0.0581     0.0213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G      1.354       1.89      1.571         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.292      0.215      0.172     0.0814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G      1.389      1.928      1.628         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.447      0.234      0.221     0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G      1.378      1.889      1.618         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.358       0.19      0.162      0.073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.6G      1.361      1.875      1.608         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.438      0.216      0.204     0.0905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G      1.325      1.786      1.576         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.553      0.271      0.286      0.146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G      1.298      1.733      1.546         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.512      0.272      0.313      0.135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.6G      1.284      1.692      1.537         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.494      0.364      0.385      0.183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G      1.274      1.657      1.529         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.584      0.398      0.434      0.202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.6G      1.243      1.608      1.496         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.658      0.449      0.475      0.241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G      1.226      1.556      1.489         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.634        0.4      0.434      0.197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.8G      1.201      1.517      1.463         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.74      0.474      0.524       0.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.476 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.738      0.474      0.524       0.26\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_10_lr_00001_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 11/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'RMSProp', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.4 ms, read: 19.6Â±13.7 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 24.1Â±21.9 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20       9.3G      2.084      3.325      2.437         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.335     0.0894    0.00309     0.0008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.762      2.607      2.051        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000715     0.0937   0.000415   0.000152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.707      2.508      1.992         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00479      0.132     0.0015   0.000451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G      1.633      2.408      1.919         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0315      0.389     0.0406     0.0132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      1.561      2.314      1.853         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.365      0.105     0.0656     0.0278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G      1.503      2.223      1.794         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.419     0.0717     0.0729     0.0262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.459      2.152      1.754         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.404      0.107     0.0456     0.0116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G      1.423      2.114      1.718         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.184      0.197      0.112      0.036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G      1.419      2.058      1.711         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.117      0.217      0.055     0.0162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G      1.368      1.982      1.675         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.253      0.118     0.0858     0.0382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G      1.442      2.044      1.795         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.375      0.289      0.232      0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G      1.421      1.985      1.768         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.326      0.208      0.153     0.0715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G      1.394      1.975       1.75         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.42      0.362      0.284      0.113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G      1.377      1.899      1.722         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.404      0.398        0.3      0.147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G      1.352      1.861      1.703         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.532      0.294      0.321      0.122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G      1.341      1.816      1.689         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.42       0.35      0.307      0.135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G      1.311      1.793      1.674         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.661      0.403      0.436      0.187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G      1.293      1.736      1.643         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:27<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.544      0.372      0.382      0.182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G      1.272      1.716      1.632         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.658      0.489      0.504      0.216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G      1.255      1.652      1.616         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:27<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.656      0.461      0.504      0.229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.470 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.66       0.45      0.506       0.23\n",
            "Speed: 0.2ms preprocess, 9.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_11_lr_00001_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 12/48\n",
            "Parameters: {'lr': 0.0001, 'optimizer': 'RMSProp', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.7Â±0.8 ms, read: 19.5Â±13.2 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 3.0Â±6.0 ms, read: 16.4Â±13.2 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.0001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.14G      2.122      3.378      2.284         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00842      0.185    0.00589    0.00113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.48G       1.77      2.613        1.9         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:13<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.362      0.105      0.008    0.00202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.84G      1.706      2.507      1.824         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.157      0.087     0.0745     0.0227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.85G      1.632      2.406      1.772        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.425     0.0726     0.0338    0.00899\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.85G       1.56      2.345      1.717         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0909      0.182     0.0469     0.0141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      5.85G      1.508      2.257      1.671         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.137       0.21     0.0722      0.023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      5.85G      1.473       2.18      1.648         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.188      0.249      0.149     0.0575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      5.89G       1.45      2.116      1.621         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.246      0.313      0.184     0.0759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20       5.9G      1.405      2.055       1.59         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.319      0.257      0.206     0.0844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20       5.9G      1.379      2.021      1.575        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.382      0.178      0.186     0.0732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20       5.9G      1.437      2.036      1.631         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.403      0.228      0.248      0.113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      5.99G       1.42      1.984      1.615         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.476      0.311      0.288      0.119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      5.99G      1.382      1.958      1.596         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.44      0.289      0.272      0.113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.11G      1.361      1.887      1.567         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.516      0.421      0.408      0.183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.11G      1.326      1.862      1.554         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.605      0.272      0.345      0.148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.11G      1.329      1.806      1.543         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.618      0.375      0.403      0.186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.11G      1.309      1.756      1.531         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.637      0.402      0.475      0.206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.11G      1.277      1.717      1.496         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.647      0.418      0.467      0.212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.11G      1.252      1.691      1.498         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.673       0.42      0.458      0.198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.11G      1.236      1.638       1.48         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.671      0.444      0.501      0.242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.453 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.672      0.444        0.5      0.242\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_12_lr_00001_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 13/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'SGD', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.5 ms, read: 20.2Â±14.6 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.4 ms, read: 17.8Â±11.3 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.3G      1.454      3.034      1.602         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.274      0.225      0.271      0.192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.4G      1.187      1.714      1.416         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.74       0.47       0.58       0.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.6G      1.054      1.307        1.3         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.817      0.636      0.728      0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.6G     0.9844      1.083       1.24         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.871      0.692      0.762      0.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.6G      0.962     0.9738       1.21         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.838       0.73      0.793      0.436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.6G     0.9284     0.8994      1.192         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.916        0.7      0.804       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.6G      0.915     0.8629      1.179         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.905      0.745      0.836      0.481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.5G     0.8876     0.8091       1.16        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908      0.748      0.834      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.6G     0.8732     0.7934      1.154        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.907      0.765      0.845      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.5G     0.8654     0.7638       1.15         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.895      0.744      0.844      0.517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.5G     0.8804     0.7032      1.153         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.89      0.775      0.855      0.522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.5G     0.8658     0.6845      1.137         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.897      0.801      0.863      0.539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.4G      0.844     0.6657      1.129         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.895      0.781      0.857      0.538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.3G     0.8301     0.6441      1.121         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.907        0.8      0.865      0.553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.3G     0.8148     0.6259      1.111         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.897       0.81      0.862      0.535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.4G     0.8078      0.609      1.102         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.873      0.805      0.865      0.565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.5G     0.8007     0.5975        1.1         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.909      0.795       0.87      0.558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.4G      0.788     0.5896      1.087         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.898      0.816      0.871      0.564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.3G     0.7826     0.5858       1.09         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.89      0.824      0.873      0.553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.5G      0.779     0.5789      1.083         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.885      0.813      0.872      0.565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.472 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887      0.816      0.872      0.566\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_13_lr_00005_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 14/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'SGD', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.0 ms, read: 27.9Â±15.0 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.3Â±1.3 ms, read: 5.1Â±5.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20       9.1G      1.443      2.861      1.606         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.334      0.268      0.287       0.19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.5G      1.164      1.677      1.402        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.719      0.574      0.623      0.339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.6G      1.041      1.291      1.292         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.803      0.646      0.731      0.393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.6G     0.9917        1.1      1.238         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908      0.653      0.772      0.429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.6G     0.9608       0.99       1.21         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.836      0.701      0.787      0.456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.6G     0.9424     0.9315      1.198         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.948      0.671      0.801      0.449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.6G     0.9132     0.8736      1.178         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.913      0.694      0.814      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.6G     0.9078      0.841      1.168         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.907      0.715      0.839      0.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.6G     0.8943     0.8177      1.164         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.912      0.725      0.833      0.486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.6G     0.8565     0.7829      1.147         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.864      0.781      0.851       0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.6G     0.8924     0.7247      1.158         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.864      0.789      0.851       0.54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.6G     0.8746     0.7088      1.147         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.913      0.764       0.86      0.553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.6G     0.8521     0.6828      1.138         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.872       0.78      0.856      0.534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.6G     0.8487      0.658       1.13         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.774      0.863      0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.6G     0.8238     0.6378      1.115         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.951      0.757      0.863      0.547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.6G     0.8201     0.6322      1.108         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.919      0.776      0.864      0.544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.6G     0.8205     0.6158      1.112         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.918      0.756      0.864      0.545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.6G     0.8058     0.6067      1.093         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.895      0.783      0.868      0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.6G     0.7982     0.6042      1.097         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.907      0.783      0.866      0.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.6G     0.7918     0.5972       1.09         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.898      0.781      0.867      0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.461 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.896      0.783      0.867      0.556\n",
            "Speed: 0.2ms preprocess, 10.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_14_lr_00005_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 15/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'SGD', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 34.0Â±17.7 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.5Â±2.6 ms, read: 11.4Â±11.6 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      4.96G       1.42      2.748      1.595         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.453      0.317      0.345      0.212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.72G      1.149      1.674      1.403         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:13<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.731       0.56      0.603       0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.73G      1.052      1.315      1.302         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.835      0.631      0.737      0.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.73G     0.9985       1.13      1.258        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.824      0.703      0.767      0.432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.76G     0.9713      1.045      1.235         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.888      0.673      0.784      0.444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.12G     0.9505     0.9708      1.213         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.881      0.709      0.808      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.12G     0.9267       0.92      1.201         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.893      0.737      0.825      0.457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.12G     0.9186     0.8787      1.179         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889      0.722      0.823      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.12G     0.8989     0.8448      1.169         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.883      0.736      0.829      0.493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.12G     0.8861     0.8331      1.163        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889       0.77      0.836      0.521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.12G      0.913     0.7655      1.171         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889       0.76       0.84      0.513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.12G     0.8947     0.7386      1.157         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.93      0.722      0.848      0.524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.12G     0.8759     0.7088      1.151         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.866      0.783      0.854      0.516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.12G      0.865     0.6915      1.135         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.911      0.766      0.856      0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.12G      0.857     0.6733      1.135         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.885      0.781      0.855      0.521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.12G     0.8427     0.6608      1.124         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.879      0.768      0.852      0.522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.12G     0.8429     0.6464      1.125         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.793      0.854      0.533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.12G     0.8329     0.6374      1.114         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.872      0.786      0.856      0.538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.12G     0.8272     0.6397      1.122         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.884      0.785      0.855      0.527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.12G     0.8182     0.6295      1.111         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.773      0.853      0.533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.449 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.873      0.786      0.856      0.538\n",
            "Speed: 0.2ms preprocess, 11.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_15_lr_00005_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 16/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'AdamW', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 38.5Â±19.1 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 14.8Â±9.3 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      1.195      1.712      1.383         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.635      0.391      0.403      0.172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.185       1.39      1.388         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.577      0.538      0.534      0.243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      1.168      1.334      1.366         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.584      0.425      0.448      0.188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G       1.14      1.291      1.345         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.639      0.521      0.536      0.294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      1.111        1.2      1.326         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.841      0.563      0.635      0.306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.065      1.147        1.3         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.704       0.55      0.594       0.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G      1.041      1.084      1.271         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.868      0.635      0.707      0.373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G     0.9898     0.9896      1.241        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.827      0.632      0.698      0.372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G     0.9772     0.9582      1.225        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.814      0.656       0.77      0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G     0.9524     0.8998      1.211         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.873      0.719      0.795      0.435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G     0.9645     0.8355      1.229         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.823      0.667      0.744      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G     0.9454     0.7957      1.215         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.906      0.725      0.798       0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.5G      0.911     0.7623      1.194         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.891      0.672      0.783      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G     0.8807     0.7111      1.171         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.922      0.745      0.834      0.513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G     0.8418     0.6598      1.146         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.742      0.842       0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G     0.8202     0.6251      1.123         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.848      0.797      0.849      0.538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G     0.7803     0.5799        1.1         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.891      0.783      0.864      0.567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G     0.7546      0.546       1.08         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.942      0.774      0.874      0.563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G     0.7222     0.5142      1.068         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.905      0.772      0.874      0.567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G     0.6938      0.492      1.049         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.955      0.758      0.873      0.593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.478 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.954      0.758      0.873      0.593\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_16_lr_00005_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 17/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'AdamW', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 1.2Â±1.1 ms, read: 18.1Â±12.4 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 35.3Â±22.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.28G        1.2      1.644      1.388         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.687      0.529      0.564      0.254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.196      1.426      1.384        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.573      0.524      0.499      0.245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.187      1.412      1.381         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.745      0.508      0.554      0.279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G      1.158      1.359      1.365         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.744      0.521      0.601      0.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      1.127      1.268      1.339         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.738      0.609      0.671      0.344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G       1.09        1.2      1.313         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.743      0.638      0.664      0.343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.045      1.134      1.283         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.859      0.617      0.698      0.357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G      1.033      1.088      1.265         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.823      0.633       0.73      0.395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G     0.9976      1.019      1.242         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.863       0.65      0.752      0.429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G     0.9504     0.9629      1.218         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.896      0.651       0.77      0.437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G     0.9926     0.8991      1.245         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.905      0.682      0.788       0.43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G     0.9611     0.8388      1.222         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.928      0.695       0.82      0.492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G     0.9302     0.7971      1.201         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.891      0.717      0.814      0.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G     0.8945     0.7403      1.173         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.746      0.825      0.502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G     0.8649     0.6908      1.157         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.934      0.738      0.841       0.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G     0.8419     0.6515      1.135         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.88       0.82      0.866      0.559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G      0.815     0.6209      1.129         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.934      0.752      0.866      0.529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G     0.7787     0.5871      1.096         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887      0.794       0.87      0.567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G      0.747     0.5603      1.081         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.876      0.811      0.876       0.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G     0.7233     0.5287      1.064         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.922       0.81      0.887      0.603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.471 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.807      0.887      0.604\n",
            "Speed: 0.2ms preprocess, 9.8ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_17_lr_00005_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 18/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'AdamW', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 37.9Â±19.4 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.9Â±1.0 ms, read: 16.6Â±16.3 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.16G      1.215      1.666      1.439         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.511      0.454      0.437      0.175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20       5.7G      1.224      1.568      1.435         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.731      0.478      0.544      0.267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.72G      1.217      1.515      1.421         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.739      0.508      0.553      0.255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.76G      1.167      1.427      1.394        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.649      0.556      0.599      0.289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.09G      1.144      1.367      1.374         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.795      0.582      0.666      0.336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.41G      1.103      1.273       1.34         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.787      0.633        0.7      0.391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.41G      1.058      1.206      1.317         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.755      0.568      0.647      0.331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.41G      1.042      1.141      1.288         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.817      0.663      0.767      0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.41G      1.006      1.077       1.27         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.88      0.658      0.754      0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.41G     0.9762      1.034      1.249        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.685       0.79      0.433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.41G     0.9966     0.9411      1.269         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.869      0.687      0.782      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.41G     0.9815       0.89      1.251         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.86      0.775      0.832      0.486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.41G     0.9535     0.8465      1.242         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.924      0.714       0.81      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.41G     0.9218     0.7897      1.207         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.732      0.815      0.489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.41G     0.8823      0.739      1.191         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.872      0.777      0.833      0.514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.45G      0.857     0.7014      1.165         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.865      0.769      0.828      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.45G     0.8294     0.6546      1.152         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.911      0.738      0.823      0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.45G     0.7945     0.6188      1.124         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.928      0.761      0.854      0.532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.45G      0.777     0.5987      1.122         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.905      0.772       0.85      0.533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.45G     0.7431     0.5627      1.092         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.93      0.736       0.86      0.553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.458 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.924      0.745      0.861      0.553\n",
            "Speed: 0.2ms preprocess, 11.3ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_18_lr_00005_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 19/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'Adam', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.7Â±0.9 ms, read: 28.9Â±24.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.6Â±2.8 ms, read: 11.5Â±12.1 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      1.192      1.718       1.39         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.63      0.313      0.374      0.171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.179       1.37      1.373         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.625      0.473      0.493      0.225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      1.158      1.319      1.362         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.712      0.546      0.583      0.275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G      1.147      1.304      1.355         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.705      0.512      0.579      0.302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      1.112      1.216      1.326         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.743      0.564      0.608      0.287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.065      1.154      1.298         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.751      0.612      0.658      0.357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G      1.035      1.083       1.27         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.812      0.576      0.651      0.352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.004      1.019      1.247        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.802      0.642      0.728      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G     0.9755     0.9638      1.224        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.858      0.634      0.736      0.412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G     0.9531     0.9127      1.214         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.804      0.688      0.759      0.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G     0.9708     0.8585      1.232         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.795      0.726      0.783      0.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G     0.9468     0.8039      1.209         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.682      0.782      0.476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.5G     0.9153     0.7723      1.193         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.876       0.73      0.819      0.484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G     0.8799     0.7206      1.168         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.907       0.75      0.841      0.545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G     0.8463     0.6635      1.143         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.913      0.724      0.818      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G     0.8156     0.6241       1.12         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.776      0.846      0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G     0.7822     0.5826      1.101         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.917      0.771      0.861      0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G      0.758     0.5499       1.08         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.872      0.822      0.875      0.565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G     0.7292     0.5218      1.071         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.919      0.765      0.873      0.562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G     0.6943     0.4947      1.049         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.818      0.878      0.597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.479 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.877      0.818      0.878      0.595\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_19_lr_00005_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 20/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'Adam', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.5 ms, read: 16.3Â±10.7 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.8Â±0.7 ms, read: 10.5Â±9.6 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.29G      1.196      1.618      1.377         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.63      0.534      0.518      0.223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.198      1.421      1.381        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.655      0.519      0.536      0.251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.183      1.403      1.373         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.79      0.489      0.574      0.288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G      1.167      1.366      1.365         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.71      0.552      0.616      0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      1.127       1.28      1.337         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.784      0.628      0.678      0.349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G      1.095      1.223      1.318         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.762      0.595      0.698       0.35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.051      1.138      1.286         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.744      0.653      0.699       0.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G      1.035      1.092      1.267         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.776      0.665      0.738      0.393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G      1.008      1.022      1.247         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.864      0.601      0.727      0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G     0.9627     0.9698      1.223         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.821      0.651      0.774      0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G     0.9986     0.9099      1.244         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.853      0.688      0.773       0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G     0.9801     0.8508      1.228         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.857      0.742      0.791      0.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G     0.9372     0.8106      1.208         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.858      0.697      0.794      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G     0.9086     0.7547      1.183         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.922      0.739      0.835      0.483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G     0.8664     0.7033      1.158         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.898       0.76      0.836      0.513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G     0.8559     0.6689      1.146         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.948      0.746      0.855      0.516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G     0.8189     0.6278      1.131         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.895      0.786      0.857      0.523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G     0.7847     0.5892      1.098         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.899      0.763      0.866      0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G     0.7562     0.5621      1.085         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908      0.799      0.865      0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G     0.7285     0.5334      1.068         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.912      0.807      0.864      0.572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.472 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.912      0.807      0.863      0.572\n",
            "Speed: 0.2ms preprocess, 9.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_20_lr_00005_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 21/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'Adam', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 34.6Â±16.6 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.9 ms, read: 20.3Â±25.2 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20       5.1G      1.213      1.655      1.414         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.647      0.403      0.485      0.216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.42G      1.218      1.539       1.42         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.714      0.446      0.513      0.255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.69G      1.209      1.499      1.404         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.77      0.526      0.559      0.222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.84G      1.175       1.42       1.38        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.748      0.554      0.614      0.295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.41G      1.142      1.365      1.352         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.797      0.563      0.647       0.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.41G      1.107      1.292      1.333         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.75      0.564      0.647      0.323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.41G      1.074       1.21      1.311         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.824      0.626      0.702      0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.41G      1.048      1.154      1.281         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.843      0.646      0.723      0.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.41G      1.014      1.097      1.262         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.823      0.639      0.735       0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.41G     0.9782      1.031      1.238        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.832      0.697      0.762      0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.41G      1.006     0.9572      1.258         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.843      0.703      0.789      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.41G     0.9837     0.9057      1.243         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.827      0.717       0.77      0.468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.41G     0.9538     0.8681      1.233         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.876      0.723      0.792      0.436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.41G     0.9286     0.8007      1.203         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.862      0.751      0.825      0.498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.41G     0.8835     0.7544      1.181         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.879      0.774       0.83      0.489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.41G     0.8627     0.7168      1.161         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.917       0.76       0.85      0.519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.41G     0.8406     0.6726       1.15         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.924      0.763      0.846      0.489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.41G     0.7999     0.6274      1.112         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.918      0.774      0.855      0.519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.42G     0.7832      0.607      1.117         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.915      0.766      0.856      0.529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.46G     0.7421     0.5666      1.085         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.876      0.791      0.862      0.547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.457 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.876      0.791      0.855      0.547\n",
            "Speed: 0.2ms preprocess, 8.2ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_21_lr_00005_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 22/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'RMSProp', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.3 ms, read: 13.6Â±12.0 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.5 ms, read: 11.2Â±11.9 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      3.144      5.544      3.166         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000133     0.0261   0.000141   2.63e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.6G      2.698      3.327      2.651         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000108     0.0221   5.76e-05      2e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G       2.34      3.105      2.274         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000136     0.0281   8.03e-05   1.92e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G      2.116      2.975      2.101         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000555     0.0484   0.000295   9.19e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      1.988      2.907      2.015         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.334    0.00201   3.54e-05   1.12e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.907      2.838      1.936         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000214     0.0442   0.000124    3.6e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G      1.881      2.815      1.934         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.667     0.0562    0.00238   0.000573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.813      2.708       1.88        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    4.6e-05    0.00803   5.89e-05   1.52e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G      1.762      2.652      1.841        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.693     0.0502     0.0215    0.00856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.8G       1.75      2.601      1.824         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G      1.821      2.731      1.904         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.46     0.0644     0.0295    0.00752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G      1.797      2.658        1.9         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00703     0.0729    0.00358   0.000794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.6G      1.752      2.627      1.876         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.681     0.0161    0.00408    0.00094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G       1.73      2.597       1.84         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0144     0.0163    0.00308   0.000654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G      1.684      2.515       1.82         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.367      0.143     0.0312     0.0082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.6G      1.667       2.48      1.786         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0035      0.044    0.00221   0.000707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G      1.642      2.467      1.777         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.345     0.0183     0.0257      0.015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G      1.605       2.39      1.743         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:25<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0312      0.232     0.0252    0.00618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G      1.564      2.345      1.724         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0444      0.143     0.0309    0.00905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G      1.529      2.287        1.7         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.301      0.103      0.113     0.0384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.478 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.301      0.102      0.113     0.0385\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_22_lr_00005_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 23/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'RMSProp', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.4 ms, read: 16.8Â±11.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 29.6Â±17.8 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.28G      2.657      4.169      3.067         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.068     0.0142    0.00702   0.000719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      2.056      2.934      2.343        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:16<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.668       0.01   0.000106   4.25e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.919      2.785       2.18         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00798     0.0142    0.00128   0.000318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G      1.844      2.735      2.111         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000137      0.106   9.13e-05   2.43e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.8G      1.792      2.661      2.063         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286        0.4     0.0547     0.0265    0.00773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.8G      1.743      2.586       2.01         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00383     0.0527     0.0024   0.000698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.8G      1.691      2.516      1.967         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.338     0.0223    0.00294    0.00116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.8G      1.649      2.496      1.929         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0254      0.102     0.0151    0.00289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.8G      1.627      2.454      1.909         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0431      0.137     0.0305     0.0108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G      1.574      2.395      1.869         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0195     0.0611     0.0155    0.00465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G      1.692      2.565      2.049         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0941      0.218     0.0687     0.0252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G      1.659      2.481      1.997         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:26<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.491     0.0783     0.0503     0.0185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G      1.615      2.443      1.971         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0787      0.082     0.0285    0.00941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G      1.606      2.405      1.946         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.361     0.0503     0.0142    0.00591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G      1.559      2.337      1.899         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.234       0.18       0.11      0.038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G      1.546      2.299      1.878         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.305      0.137      0.119     0.0362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G      1.521      2.261      1.871         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.309      0.154      0.111     0.0405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G      1.492      2.207      1.825         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.414       0.23      0.164     0.0558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G      1.469       2.18       1.81         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.541      0.147      0.154     0.0601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G      1.441      2.114       1.79         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.427      0.235      0.237       0.09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.468 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.427      0.235      0.237     0.0899\n",
            "Speed: 0.2ms preprocess, 9.8ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_23_lr_00005_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 24/48\n",
            "Parameters: {'lr': 0.0005, 'optimizer': 'RMSProp', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.2Â±0.0 ms, read: 30.1Â±17.3 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.7 ms, read: 24.6Â±13.7 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.0005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.13G      2.402       3.67      2.516         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00675    0.00602   0.000282   6.63e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.68G       1.94      2.811      2.031         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:13<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.379     0.0804    0.00576    0.00152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      6.04G      1.847      2.709      1.928         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.688    0.00813     0.0102    0.00216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      6.05G       1.78      2.649      1.888        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00122     0.0933   0.000641   0.000163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.09G      1.704      2.566      1.829         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.354     0.0263     0.0052    0.00139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20       6.1G      1.653      2.528      1.782         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.43     0.0183     0.0251    0.00811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20       6.1G      1.628      2.458      1.759         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0171     0.0462    0.00674    0.00172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20       6.1G      1.609      2.408      1.732         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.126      0.078     0.0563     0.0159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.13G      1.573      2.378      1.706         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.193      0.184     0.0847     0.0223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.13G      1.529      2.319      1.673        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0458     0.0582     0.0198    0.00862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.13G      1.614      2.405      1.753         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.104        0.1     0.0738     0.0235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.13G      1.594      2.352      1.749         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.23      0.104     0.0806     0.0227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.13G      1.551      2.318      1.718         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.263      0.137      0.128     0.0529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.13G      1.518      2.244      1.685         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.381      0.189      0.172     0.0663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.13G      1.482      2.197      1.667         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:23<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.221      0.106     0.0892     0.0348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.13G      1.483      2.182      1.655         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.281      0.157      0.143     0.0618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.13G      1.446      2.115      1.622         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.28      0.226      0.176      0.078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.13G      1.418      2.082        1.6         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:23<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.49      0.292      0.292      0.122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.13G      1.395      2.032      1.589         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:23<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.434      0.261      0.265     0.0986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.13G      1.371      1.973       1.57         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.538      0.242      0.313      0.151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.456 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.541      0.242      0.314      0.151\n",
            "Speed: 0.2ms preprocess, 8.6ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_24_lr_00005_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 25/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.3 ms, read: 17.3Â±10.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 42.2Â±17.7 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.3G      1.413      2.782      1.573         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.583      0.452       0.46      0.288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.4G      1.095      1.454      1.343         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.851      0.581      0.688      0.372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.6G      1.004      1.128      1.254         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.826      0.709      0.758       0.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.6G     0.9565     0.9665      1.214         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.91      0.701      0.815      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.6G     0.9283     0.8799      1.192         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.921      0.714      0.817      0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.6G     0.8951     0.8199       1.17         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.938      0.723      0.831      0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.6G     0.8745     0.7829      1.148         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.952      0.785      0.864      0.542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.5G     0.8497     0.7272      1.129        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286        0.9      0.776      0.854       0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.6G     0.8297      0.709      1.118        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.934       0.76      0.861      0.531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.6G     0.8181     0.6789      1.114         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.91      0.791       0.87      0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.5G     0.8226     0.6114      1.108         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.918      0.813      0.886      0.589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.5G      0.806     0.5858      1.093         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.927      0.793      0.881      0.592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.4G     0.7798     0.5692      1.088         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.918       0.79      0.878      0.569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.3G     0.7643     0.5425      1.079         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.925      0.782      0.882      0.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.3G     0.7467     0.5262      1.061         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.909      0.801      0.884      0.587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.3G     0.7262      0.508      1.046         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.913      0.812      0.889      0.608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.5G     0.7133     0.4915      1.041         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.923      0.799      0.884      0.596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.4G      0.706     0.4844      1.032         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.891      0.818      0.886      0.603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.3G     0.6967     0.4766      1.034         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.933      0.802      0.887      0.607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.6G     0.6852     0.4661      1.026         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.928      0.793      0.888      0.612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.471 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.929      0.793      0.888      0.612\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_25_lr_0001_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 26/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 6.8Â±13.9 ms, read: 17.1Â±11.0 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.8Â±1.3 ms, read: 19.5Â±17.5 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20       9.1G      1.391      2.605      1.567         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.584      0.437      0.468      0.266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.5G      1.087      1.439      1.338        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.827      0.651        0.7      0.377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.6G      1.004      1.137      1.261         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.803      0.702      0.772      0.435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.6G     0.9683     0.9919      1.224         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.829      0.713      0.792      0.444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.6G     0.9372     0.9099      1.194         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.874      0.707      0.802      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.6G     0.9191     0.8625      1.189         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.917      0.708      0.825      0.481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.6G     0.8816     0.8045      1.168         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.903      0.771      0.842      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.6G     0.8745     0.7693      1.153         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.866      0.781      0.849      0.525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.6G      0.857     0.7397      1.143         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.906      0.755      0.848      0.519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.6G     0.8138     0.7043      1.126         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.764       0.86      0.561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.6G     0.8428     0.6278      1.127         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908       0.75      0.858      0.573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.6G     0.8253     0.6156      1.112         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.919      0.734      0.858      0.584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.6G     0.8001     0.5866      1.097         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.911      0.777      0.881      0.579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.6G     0.7791     0.5613      1.078         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.858      0.806      0.881      0.592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.6G     0.7587     0.5422      1.066         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.901      0.785      0.894      0.579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.6G     0.7496     0.5289      1.062         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.946      0.775      0.885      0.597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.6G      0.742     0.5148      1.063         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.869      0.819      0.884      0.584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.6G     0.7292      0.502      1.046         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.936      0.787      0.883      0.593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.6G     0.7176     0.4984      1.045         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.931      0.788       0.89      0.599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.6G     0.7064     0.4865      1.039         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.899      0.798      0.891      0.603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.464 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.899      0.798      0.891      0.604\n",
            "Speed: 0.2ms preprocess, 11.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_26_lr_0001_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 27/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'SGD', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 23.3Â±14.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 30.0Â±19.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      4.95G      1.367      2.496      1.555         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.674      0.438      0.508       0.28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.49G      1.078      1.453      1.337         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:13<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.771      0.613      0.689      0.359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.84G      1.011      1.167      1.256         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.92      0.631      0.752      0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.84G     0.9794      1.028      1.226        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.874      0.686      0.807      0.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.84G     0.9514     0.9493       1.21         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.923      0.691      0.808      0.481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      5.84G     0.9245     0.8904      1.196         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.709      0.813      0.458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      5.84G     0.8984     0.8419      1.182         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887      0.746      0.839      0.491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      5.84G     0.8883     0.7982      1.158         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.836      0.777      0.843      0.493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      5.87G     0.8675     0.7651      1.148         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.906      0.745      0.864      0.533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20       5.9G     0.8462     0.7454      1.139        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.913      0.764      0.859      0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      5.92G     0.8655      0.666      1.138         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.876      0.784      0.863      0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      5.92G     0.8445     0.6398      1.122         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.901       0.76      0.868      0.574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      5.92G     0.8157     0.6106      1.114         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.902      0.786      0.876      0.561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      5.92G     0.8013      0.589      1.098         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.933      0.769      0.887      0.576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      5.92G     0.7838     0.5672      1.091         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.923      0.807      0.891      0.584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      5.92G     0.7668     0.5521      1.079         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.977       0.74      0.879      0.585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      5.92G     0.7623     0.5402      1.078         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.944      0.738      0.879      0.571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      5.92G     0.7542     0.5298      1.069         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.942      0.742      0.876       0.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      5.92G     0.7425     0.5264      1.072         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.975      0.728       0.88      0.582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      5.92G     0.7296     0.5144      1.059         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.973      0.731       0.88      0.597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.451 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.974      0.731       0.88      0.598\n",
            "Speed: 0.2ms preprocess, 8.1ms inference, 0.0ms loss, 9.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_27_lr_0001_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 28/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'AdamW', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 7.1Â±14.5 ms, read: 16.7Â±10.4 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.8 ms, read: 22.2Â±16.2 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.4G      1.253      1.822      1.439         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.333      0.212      0.151     0.0631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.295      1.635      1.468         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.393      0.344      0.242     0.0934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      1.267      1.572      1.449         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.456      0.338      0.306      0.123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G      1.231      1.519      1.419         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.573       0.45      0.416      0.196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G       1.19      1.419      1.391         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.678      0.502       0.55      0.264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.137      1.344      1.362         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.505      0.457      0.415      0.203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G       1.12      1.271      1.331         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.655      0.574       0.59      0.285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.072      1.181      1.303        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.781      0.554      0.628      0.303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G      1.052      1.141      1.282        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.705      0.624      0.675      0.365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G      1.032      1.083      1.273         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.775      0.617      0.688      0.344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G      1.058      1.027      1.304         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.877      0.633      0.733      0.395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G      1.033     0.9776      1.277         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.853      0.618      0.718      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.5G      1.007     0.9338      1.266         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.856      0.652      0.746      0.394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G     0.9773     0.8775      1.238         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.875      0.703      0.797      0.441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G     0.9361     0.8178      1.213         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.842      0.707      0.795      0.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G     0.9064     0.7769       1.19         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.851      0.741      0.798      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G     0.8719     0.7352       1.17         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.863       0.72      0.802      0.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G     0.8425     0.6895      1.141         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.923      0.691       0.81       0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G     0.8094     0.6451      1.133         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.923      0.731      0.835      0.506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G     0.7819     0.6115      1.111         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.901      0.757      0.838      0.533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.480 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.89       0.76      0.844      0.534\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_28_lr_0001_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 29/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'AdamW', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 16.7Â±12.3 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 30.3Â±15.9 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.28G      1.275      1.768      1.467         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.52      0.447      0.355      0.143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.324      1.705      1.508        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.579      0.408      0.382      0.159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.292      1.662       1.48         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.485      0.415      0.349      0.172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G      1.243      1.585      1.442         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.588      0.426      0.467      0.224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      1.204      1.482      1.412         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.584      0.529       0.54      0.253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G      1.168      1.396      1.379         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.715      0.543      0.589      0.273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.125        1.3      1.347         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.744      0.599       0.65      0.301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G      1.105      1.246      1.323         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.717      0.622      0.659       0.35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G      1.079      1.196      1.312         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.83      0.594      0.692      0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G      1.021      1.127      1.279         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.825      0.606      0.685      0.326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G      1.067      1.071      1.315         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.794      0.624       0.67      0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G      1.048      1.021      1.302         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.789      0.698      0.742       0.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G      1.008     0.9587      1.277         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.89      0.636      0.749        0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G     0.9856     0.8946      1.249         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.87      0.665      0.766      0.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G     0.9485     0.8438      1.228         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.833      0.693      0.753      0.413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G     0.9344     0.8147      1.216         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.837      0.726      0.804      0.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G     0.9031     0.7636      1.201         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.876      0.718      0.798      0.484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G     0.8681     0.7152      1.163         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.895      0.728      0.834      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G     0.8381     0.6817      1.153         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.919      0.709       0.82      0.499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G     0.8096     0.6478      1.133         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.955      0.722      0.842      0.529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.472 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.953      0.722      0.841      0.528\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_29_lr_0001_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 30/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'AdamW', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 7.4Â±15.3 ms, read: 20.8Â±14.2 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 13.9Â±15.8 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20       5.2G      1.309      1.843      1.503         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:18<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.421      0.261      0.241     0.0897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.96G      1.346      1.837      1.529         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.472      0.343       0.34      0.162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20         6G      1.326      1.767      1.498         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.535      0.475      0.458        0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      6.04G       1.26       1.67       1.46        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.554      0.456      0.486      0.222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.04G      1.225      1.593      1.434         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.723      0.514      0.556      0.275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.04G      1.189      1.499      1.403         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.723      0.531       0.58      0.272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.04G      1.143      1.421      1.378         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.742      0.573      0.603      0.267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.04G      1.121      1.335      1.353         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.734      0.527      0.645      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.04G      1.084      1.271      1.325         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.815      0.592      0.668      0.361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.39G      1.055      1.232      1.303        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.834      0.618      0.691      0.365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.39G      1.089      1.148      1.336         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.777      0.638      0.721      0.377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.39G      1.067      1.096       1.32         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914       0.63      0.756      0.438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20       6.4G      1.034      1.036      1.299         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.87      0.671      0.769      0.399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.41G      1.011     0.9882      1.271         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.875      0.694      0.779      0.439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.41G     0.9696     0.9273      1.256         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887      0.652      0.784      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.41G     0.9518     0.8772      1.235         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.843      0.734      0.809      0.487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.41G     0.9251      0.813      1.217         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.877       0.72      0.806      0.456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.41G     0.8924     0.7836      1.188         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.721      0.826       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.41G     0.8688     0.7535      1.182         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.874      0.743      0.814       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.41G     0.8329     0.7023      1.149         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.884      0.753      0.833        0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.460 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.885      0.753      0.833        0.5\n",
            "Speed: 0.2ms preprocess, 8.4ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_30_lr_0001_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 31/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 3.9Â±7.3 ms, read: 25.7Â±14.0 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 5.4Â±11.3 ms, read: 13.7Â±12.2 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      1.262      1.837      1.429         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.225      0.366      0.214      0.086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.311      1.669      1.475         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.482      0.448      0.408      0.165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      1.266      1.578      1.445         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.479       0.34      0.307      0.125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G      1.234      1.533      1.418         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.697      0.477       0.52      0.252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      1.188       1.43       1.39         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.643      0.485      0.502      0.254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.149      1.355      1.365         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.727      0.489      0.568      0.269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G      1.126       1.29      1.333         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.728      0.583      0.618      0.298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.079      1.207      1.304        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.724      0.541      0.611      0.335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G      1.063      1.165      1.286        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.868      0.571      0.681      0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.8G      1.043      1.091      1.279         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.866      0.609      0.695      0.355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G      1.068       1.04      1.306         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:25<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.76       0.61      0.698      0.374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G      1.049      1.009      1.289         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.871      0.643      0.713      0.394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.6G      1.016     0.9707      1.274         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.802      0.696      0.753      0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G     0.9926     0.9166      1.254         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.836      0.682      0.772      0.419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G     0.9523     0.8508      1.228         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.872      0.703      0.787      0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G     0.9185     0.7988      1.194         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.922      0.707      0.816      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G     0.8902     0.7539      1.179         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.881      0.747       0.82       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G     0.8583     0.7087       1.15         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.744      0.831      0.487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G     0.8259     0.6675       1.14         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.925      0.728       0.84      0.512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G     0.7887     0.6281      1.113         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908      0.753      0.855      0.534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.481 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908      0.753      0.855      0.535\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_31_lr_0001_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 32/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 8.7Â±17.9 ms, read: 17.4Â±10.2 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.8 ms, read: 16.2Â±13.6 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.28G      1.278       1.78      1.445         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.459      0.298      0.303      0.119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.319      1.706      1.488        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.424       0.24      0.222      0.103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.304      1.672      1.469         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.575      0.407      0.451      0.216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G      1.253      1.598      1.433         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.587      0.508      0.477      0.216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      1.205      1.484       1.41         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.652       0.56      0.546      0.257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G      1.166      1.417      1.379         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.719      0.561      0.592      0.265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.124      1.329      1.343         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.741      0.578      0.625      0.275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G        1.1      1.273      1.324         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.703      0.591      0.648       0.33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G      1.079      1.214      1.309         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.798       0.58      0.678      0.367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G      1.026      1.145      1.277         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.834      0.641      0.724      0.363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G       1.08      1.101      1.315         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.814      0.595       0.65      0.323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G      1.052      1.056      1.295         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.862      0.653      0.722      0.395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G      1.034      1.017      1.288         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.798      0.596      0.701      0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G      1.003     0.9352      1.257         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.833      0.679       0.76      0.421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G     0.9671     0.8818      1.233         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.927      0.701      0.809      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G     0.9535     0.8476      1.219         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.908      0.699      0.805      0.453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G     0.9115     0.7884      1.199         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.887      0.711       0.81      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G     0.8747     0.7447      1.164         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.909      0.721      0.817      0.476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G     0.8537     0.7082      1.155         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.945      0.704      0.819      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G     0.8206     0.6651      1.133         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.951      0.723      0.831      0.518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.472 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.951      0.723      0.832      0.518\n",
            "Speed: 0.2ms preprocess, 10.6ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_32_lr_0001_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 33/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'Adam', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 6.8Â±14.0 ms, read: 18.8Â±13.6 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.4 ms, read: 16.2Â±17.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.15G      1.306      1.858      1.498         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:18<00:00,  4.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.518      0.264      0.294     0.0964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.91G      1.352       1.85      1.542         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.544      0.394       0.36      0.158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.94G      1.329      1.774       1.51         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.503      0.376      0.382      0.164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.94G      1.257      1.669      1.467        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.531      0.506      0.486      0.218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.94G      1.218      1.573      1.439         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.769      0.461      0.533       0.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      5.94G      1.181        1.5       1.41         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.703      0.526      0.558      0.257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      5.94G      1.148      1.424      1.392         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.714      0.531      0.576      0.278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      5.94G       1.12      1.348      1.362         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.73      0.593       0.65      0.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      5.98G      1.091      1.288       1.34         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.79      0.604      0.667      0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.34G      1.058      1.246      1.319        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.816      0.574       0.67      0.372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.34G      1.102      1.194      1.358         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.787      0.605       0.66      0.338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.34G      1.073      1.135       1.34         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.817      0.645      0.726      0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.34G      1.034      1.066      1.319         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.869      0.683      0.754      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.34G      1.011          1      1.286         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.819      0.679      0.758      0.418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.34G     0.9838     0.9461      1.276         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.875      0.714      0.792      0.445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.34G     0.9613     0.9068      1.249         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.857      0.723      0.782      0.457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.34G      0.931     0.8406      1.234         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.849      0.658      0.718      0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.34G     0.8999     0.8002      1.204         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.874      0.708      0.797      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.35G     0.8691      0.764      1.192         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.86      0.728      0.773      0.439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.35G     0.8403      0.722      1.165         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.839      0.735        0.8      0.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.464 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.841      0.734        0.8      0.469\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_33_lr_0001_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 34/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'RMSProp', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 22.6Â±17.5 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 39.3Â±20.3 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      3.165      7.384       3.11         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00147     0.0647   0.000739   0.000176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.6G      2.871      3.466       2.74         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   1.98e-05     0.0163   1.03e-05   1.53e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      2.612      3.284      2.464         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00139      0.118    0.00104   0.000261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.8G      2.391      3.172      2.297         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.67     0.0161   0.000921    0.00022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      2.202      3.001      2.158         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   4.02e-05    0.00402   2.08e-05   2.08e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      2.097      2.939      2.077         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000177     0.0364   0.000104   2.58e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G      2.059      2.917      2.032         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000153     0.0241   8.78e-05   2.27e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.985      2.846      1.994        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G      1.908      2.794      1.916        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      4e-05    0.00201   2.03e-05   1.02e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.8G      1.908      2.752      1.908         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00038     0.0904   0.000245   6.29e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G      1.909      2.842      1.996         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00172      0.238    0.00436   0.000915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G      1.892      2.793      1.974         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000542       0.01   0.000285   7.43e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.6G      1.843      2.732      1.953         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G      1.812       2.67      1.909         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0036      0.174    0.00393    0.00115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G       1.75      2.576      1.876         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:25<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00149     0.0201   0.000381   9.28e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.6G      1.742      2.542      1.857         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.675     0.0407    0.00569    0.00126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G      1.703      2.515      1.836         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.414      0.091     0.0369    0.00862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G      1.663      2.459      1.786         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.668       0.01    0.00016   3.63e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G      1.637      2.426      1.775         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0173       0.24     0.0226    0.00799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G       1.58      2.344      1.741         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0571      0.101     0.0348      0.011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.477 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0525     0.0967     0.0338     0.0109\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_34_lr_0001_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 35/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'RMSProp', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 12.6Â±12.0 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 28.1Â±20.9 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20       9.3G      2.968      4.944      3.005         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000478     0.0804   0.000293   6.94e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      2.543      3.294      2.488        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:16<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.337    0.00602    0.00143   0.000282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      2.271      3.047      2.216         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000446     0.0602   0.000429    0.00011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G       2.12      2.941       2.13         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000266     0.0162   0.000141   2.99e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      2.021      2.849       2.03         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0669     0.0523     0.0409     0.0164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G      1.941      2.796      1.977         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000137     0.0281   7.58e-05   1.54e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.859      2.718       1.92         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00171      0.224     0.0152    0.00232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G       1.83      2.682      1.892         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00192     0.0842    0.00117   0.000366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G      1.794      2.648      1.874         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.335     0.0361    0.00118   0.000333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G      1.741      2.552      1.829         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0148      0.177     0.0294    0.00719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G      1.798      2.654      1.906         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0253      0.185     0.0576     0.0215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G      1.765      2.603      1.884         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0031     0.0565     0.0017   0.000398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G      1.713      2.557      1.851         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00705      0.209     0.0167    0.00498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G      1.696      2.513      1.829         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00341     0.0697    0.00231   0.000495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G      1.667      2.458      1.806         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0296      0.177     0.0212    0.00788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G      1.638      2.405      1.784         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.017       0.18     0.0116    0.00346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G      1.602      2.342      1.762         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.014     0.0964     0.0399    0.00904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G      1.586      2.332      1.735         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00733      0.156    0.00717     0.0024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G      1.565      2.298      1.725         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.287      0.136      0.136     0.0534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G       1.53      2.223      1.703         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:25<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0666     0.0891     0.0449     0.0112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.461 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.292      0.138      0.137      0.053\n",
            "Speed: 0.2ms preprocess, 9.3ms inference, 0.1ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_35_lr_0001_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 36/48\n",
            "Parameters: {'lr': 0.001, 'optimizer': 'RMSProp', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 23.4Â±14.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.9Â±1.0 ms, read: 25.4Â±19.4 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.21G      2.854      4.072      3.046         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.06     0.0244     0.0292     0.0104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.76G      2.416      3.253      2.474         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:13<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.667    0.00803   4.88e-05   1.27e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20       5.8G      2.161      3.063      2.235         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000148     0.0281   8.02e-05   3.01e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20       5.8G      1.997       2.99      2.139        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.674       0.01    0.00287   0.000822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.17G      1.936      2.932      2.084         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000227    0.00803   4.98e-05   1.81e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.17G      1.874      2.905      2.027         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000371     0.0723   0.000231   5.34e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.17G      1.784      2.826      1.956         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.706     0.0502     0.0129    0.00333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.17G      1.777        2.8      1.935         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00134      0.149    0.00276   0.000562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.17G      1.745      2.719      1.907         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.672    0.00402     0.0122    0.00258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.17G      1.673      2.634      1.858        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0245     0.0682    0.00869    0.00249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.17G      1.763      2.736      1.936         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:19<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.417     0.0488     0.0387     0.0141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.17G      1.729      2.686      1.919         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.12     0.0971     0.0328    0.00906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.17G      1.675      2.629      1.886         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.69     0.0324     0.0504     0.0127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.17G      1.666      2.571       1.86         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.45     0.0607     0.0503     0.0168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.17G      1.623      2.489      1.823         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:24<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.114      0.058     0.0558     0.0139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.17G      1.599      2.475       1.81         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0152      0.212     0.0269    0.00887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.17G      1.575      2.414      1.789         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.229      0.125     0.0956     0.0274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.21G      1.533      2.369      1.758         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:24<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.33      0.097      0.081     0.0279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.21G      1.517      2.337      1.756         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.118      0.208     0.0698     0.0263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.21G      1.496      2.285      1.729         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:18<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.311      0.212      0.155     0.0531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.450 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.313      0.212      0.157     0.0539\n",
            "Speed: 0.2ms preprocess, 9.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_36_lr_0001_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 37/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'SGD', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.3 ms, read: 19.0Â±14.3 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 37.3Â±21.8 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      1.314      2.374      1.498         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.727      0.556      0.611      0.323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.4G      1.014      1.174      1.259         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.879      0.641      0.753      0.429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.6G     0.9827     0.9998      1.223         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.867      0.634      0.754      0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.6G     0.9682     0.9403      1.214         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.837      0.697      0.786       0.46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.6G     0.9412     0.8701      1.193         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.859      0.743      0.825      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.6G     0.9102     0.8159      1.164         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.846      0.776      0.862      0.522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.6G     0.8908      0.768      1.152         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.911      0.753      0.859       0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.5G     0.8497     0.7076      1.128        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.884      0.822      0.884      0.529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.6G     0.8359     0.6878      1.113        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.931      0.778       0.88      0.569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.6G     0.8136     0.6522       1.11         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.915      0.796      0.883      0.579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.5G     0.8248     0.5856      1.105         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.856      0.828      0.887      0.562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.5G     0.7906     0.5582      1.087         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:20<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.846      0.818      0.875      0.602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.4G     0.7702     0.5362      1.074         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.798      0.887      0.613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.3G      0.742     0.5013      1.055         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.945      0.811      0.908      0.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.3G     0.7242     0.4745      1.035         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.936      0.817      0.908      0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.4G     0.6933     0.4506      1.012         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.928       0.85      0.918      0.641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.5G     0.6725     0.4328      1.008         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.898      0.839       0.92      0.631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.4G     0.6547     0.4139     0.9917         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.934      0.845       0.91      0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.3G     0.6357     0.4017     0.9874         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.951      0.834      0.917      0.642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.6G     0.6137     0.3855      0.977         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.936      0.835       0.92      0.661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.474 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.936      0.835       0.92       0.66\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_37_lr_0003_optimizer_SGD_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 38/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'SGD', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.2 ms, read: 23.3Â±13.4 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 40.8Â±21.5 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20       9.1G      1.279      2.173      1.482         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.722      0.582      0.649      0.344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.5G      1.021      1.175      1.271        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.879      0.681      0.784      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.6G     0.9873      1.021      1.233         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.827      0.703       0.79      0.433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.6G     0.9777     0.9576      1.215         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.851      0.738      0.791      0.466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.6G     0.9654     0.8889      1.196         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.867      0.701      0.791      0.494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.6G     0.9361     0.8416      1.187         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.863      0.701      0.801       0.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.6G     0.8984     0.7938      1.164         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.732      0.829       0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.6G      0.887     0.7502      1.151         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.895      0.768      0.856      0.547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.6G      0.858     0.7192      1.145         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.844      0.758      0.831      0.518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.6G     0.8131     0.6779       1.12         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.858      0.803      0.858      0.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.6G     0.8386     0.6001      1.122         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.896      0.812       0.89      0.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.6G     0.8164     0.5866      1.107         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.93      0.821      0.902      0.616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.6G     0.7816     0.5493      1.083         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.923      0.808      0.886      0.618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.6G     0.7605     0.5207      1.066         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.922       0.79      0.884      0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.6G       0.73     0.4901       1.05         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.94      0.798      0.897      0.615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.6G     0.7117     0.4693      1.041         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.939      0.834      0.901      0.643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.6G     0.6929     0.4457      1.033         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.939      0.823      0.903      0.616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.6G     0.6709     0.4295       1.01         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.916      0.875      0.913      0.632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.6G     0.6572     0.4248      1.009         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.953      0.824      0.908      0.638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.6G     0.6342     0.4025     0.9959         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.954      0.831      0.913      0.645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.464 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.954      0.832      0.913      0.645\n",
            "Speed: 0.2ms preprocess, 9.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_38_lr_0003_optimizer_SGD_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 39/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'SGD', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 7.6Â±16.3 ms, read: 26.9Â±23.6 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.8Â±1.0 ms, read: 19.2Â±23.4 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      4.93G      1.253      2.076      1.467         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.853      0.566      0.663      0.336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.48G      1.017      1.199      1.269         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.779      0.676      0.755      0.438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.83G     0.9956      1.049      1.235         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.782      0.706      0.781       0.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.83G     0.9908     0.9954      1.246        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.892      0.687      0.807      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.83G     0.9712     0.9548      1.218         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.797      0.738      0.795      0.456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      5.83G     0.9444     0.8894      1.212         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.831      0.737      0.821      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      5.83G     0.9167      0.831      1.186         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.899      0.684      0.812      0.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      5.83G     0.8917     0.7841      1.158         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.878      0.787      0.873      0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      5.84G     0.8671     0.7507      1.151         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.962      0.733      0.875      0.547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      5.86G     0.8423     0.7235       1.14        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.894      0.788       0.87      0.569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      5.89G     0.8606     0.6374       1.14         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286        0.9      0.804      0.889      0.568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      5.89G     0.8384     0.6096      1.118         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.906       0.78      0.891      0.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      5.89G     0.8019     0.5756      1.102         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.902      0.799      0.887      0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      5.89G     0.7875     0.5508      1.089         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.899      0.822      0.904      0.617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      5.89G     0.7516      0.512      1.065         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.879      0.867        0.9      0.601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      5.89G     0.7284     0.4965      1.056         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.866      0.858      0.901       0.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      5.92G     0.7161     0.4765       1.05         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.914      0.848      0.902      0.602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      5.92G     0.6924     0.4546       1.03         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.892      0.882      0.917      0.618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      5.92G     0.6749      0.449      1.028         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.955       0.81      0.919      0.617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      5.92G     0.6581     0.4262      1.014         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.905      0.845      0.918      0.622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.451 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.905      0.845      0.918      0.624\n",
            "Speed: 0.2ms preprocess, 8.3ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_39_lr_0003_optimizer_SGD_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 40/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'AdamW', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 21.9Â±17.1 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 28.3Â±18.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      1.439       2.18      1.584         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00138      0.162    0.00101   0.000359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.506      2.121      1.624         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0211      0.204     0.0163    0.00653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      1.432      1.932       1.57         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0435      0.137     0.0185    0.00536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G      1.359      1.826      1.519         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.402      0.249      0.224      0.101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      1.307      1.739      1.486         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.515      0.378       0.33      0.152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.252      1.648      1.448         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.587      0.316       0.32      0.162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.8G      1.234      1.599      1.426         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.534      0.372      0.423      0.195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.185      1.485      1.398        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.692      0.475      0.528      0.264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G      1.162      1.439      1.378        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.637      0.512       0.56      0.271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G      1.139       1.36      1.362         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.791      0.517      0.601      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G      1.183      1.337      1.421         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:24<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.75      0.529      0.579      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G      1.156      1.294      1.396         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.84      0.594       0.68      0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.5G      1.139      1.258      1.383         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.734      0.584      0.659      0.315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G      1.101      1.179      1.352         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.77        0.6      0.669      0.346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G      1.084      1.123      1.335         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.792      0.612      0.708      0.376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G      1.058      1.082      1.313         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.787      0.626      0.707      0.394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G      1.021      1.016      1.289         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.84      0.636      0.746      0.379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G     0.9946     0.9688      1.257         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.86      0.678      0.753      0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G     0.9651     0.9047      1.245         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.947      0.626      0.756      0.441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G      0.934     0.8688      1.221         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.848      0.683      0.781      0.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.481 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.844      0.684      0.781       0.46\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_40_lr_0003_optimizer_AdamW_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 41/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'AdamW', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.4 ms, read: 18.2Â±13.7 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 3.3Â±6.5 ms, read: 12.9Â±12.1 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.28G      1.474      2.152      1.588         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.198      0.279      0.131     0.0454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.502      2.098      1.616        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.238      0.212      0.133     0.0565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.425      2.003      1.565         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.427      0.378      0.267      0.118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G       1.35      1.887      1.519         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.48      0.351      0.347      0.154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      1.318      1.771      1.484         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.52      0.376      0.373      0.141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G      1.263      1.696      1.448         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.542      0.418       0.43      0.179\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.223      1.597      1.412         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.702      0.453      0.516      0.222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G      1.204      1.548      1.402         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.677      0.483      0.545      0.253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G       1.18      1.482      1.382         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.688      0.458      0.514      0.245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G      1.127      1.434      1.355         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286        0.7      0.539      0.574      0.267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G      1.187      1.407      1.415         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:24<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.786      0.532      0.592      0.294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G      1.179      1.351      1.404         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.758      0.566      0.613      0.326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G      1.147      1.302      1.389         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.792      0.571      0.642      0.297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G      1.121      1.229      1.359         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.768      0.581      0.631      0.334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G      1.094      1.177      1.338         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.693       0.66      0.677      0.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G      1.076      1.131      1.321         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.848      0.618      0.707      0.375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G       1.04      1.058      1.299         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.82      0.666      0.723      0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G      1.012      1.012      1.271         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.841      0.696      0.746      0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G     0.9845     0.9696      1.258         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.809      0.662      0.739      0.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G     0.9559     0.9173      1.236         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.884      0.696      0.767      0.428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.473 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.875      0.696      0.766      0.428\n",
            "Speed: 0.4ms preprocess, 9.9ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_41_lr_0003_optimizer_AdamW_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 42/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'AdamW', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 7.3Â±14.9 ms, read: 17.1Â±11.5 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.8Â±1.0 ms, read: 24.1Â±17.1 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.18G      1.501      2.218      1.628         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:18<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.067      0.277       0.04     0.0158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.51G      1.499      2.192      1.639         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.27      0.236      0.177     0.0735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.85G      1.443      2.054      1.587         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.416       0.29      0.227     0.0833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.85G      1.363      1.946      1.537        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.604      0.391      0.388      0.157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      5.86G      1.324      1.847      1.499         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.438      0.405      0.333      0.158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      5.86G      1.297      1.808      1.474         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.683      0.435      0.494       0.23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      5.86G       1.24      1.691      1.449         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.667      0.487      0.493      0.216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      5.86G      1.231      1.634      1.428         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.645      0.488      0.551      0.261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      5.86G      1.182       1.55        1.4         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.666      0.508      0.546      0.286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      5.86G      1.158      1.528       1.38        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.671      0.542      0.567      0.287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      5.86G      1.201      1.473      1.425         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.72      0.516       0.58      0.278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      5.86G      1.191      1.427       1.42         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.736      0.554      0.644      0.334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      5.86G      1.168      1.392      1.408         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.714      0.591      0.626      0.305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      5.86G      1.139      1.307       1.37         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.798      0.563      0.647      0.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      5.86G      1.112       1.26      1.362         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.796      0.616       0.67      0.337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      5.88G      1.089      1.198      1.338         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.76      0.643      0.694      0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      5.88G      1.067      1.139      1.326         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.73      0.654      0.691      0.357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20       5.9G      1.029      1.093      1.289         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.841      0.668      0.753      0.414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      5.96G      1.002      1.052      1.281         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.804       0.63        0.7      0.365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.05G     0.9779     0.9911      1.257         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.875       0.64      0.738      0.412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.459 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.841      0.668      0.752      0.414\n",
            "Speed: 0.2ms preprocess, 8.3ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_42_lr_0003_optimizer_AdamW_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 43/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'Adam', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.2 ms, read: 35.3Â±17.3 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 45.4Â±19.8 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      1.431      2.164      1.573         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000864      0.113   0.000571   0.000142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.5G      1.498      2.093      1.624         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.181      0.132      0.057     0.0246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      1.412      1.925      1.562         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.294      0.242      0.199     0.0767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G       1.37       1.86      1.528         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.321      0.261      0.235     0.0967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G      1.326       1.78      1.501         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.449      0.379       0.33       0.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G      1.268      1.679      1.466         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.498      0.431      0.417      0.178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.7G      1.234      1.598      1.433         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.655      0.446      0.439      0.183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G      1.191      1.502      1.402        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.733      0.452      0.532      0.259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G      1.184      1.469      1.389        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.684      0.445      0.499      0.227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G      1.161      1.401      1.379         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.667      0.478      0.514      0.251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G      1.212      1.394      1.438         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.709       0.54      0.603      0.298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G      1.194      1.362      1.425         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.716      0.546      0.569       0.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.5G      1.177      1.327      1.412         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.746      0.522      0.594      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G       1.14      1.251      1.381         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.716      0.583      0.636      0.303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G       1.11      1.182      1.358         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.746      0.597      0.657      0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G      1.089      1.147      1.339         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:22<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.764      0.619      0.668      0.344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G      1.052      1.071      1.315         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.874      0.599      0.717      0.356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G      1.023      1.007       1.28         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.902      0.665      0.761      0.391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G     0.9887     0.9485      1.269         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:23<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.893      0.656      0.751      0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G     0.9518     0.9005       1.24         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.869       0.68       0.76      0.415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.481 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.87       0.68       0.76      0.415\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_43_lr_0003_optimizer_Adam_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 44/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'Adam', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 18.2Â±13.5 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 32.7Â±16.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.28G      1.468      2.166      1.597         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.105      0.159     0.0818     0.0282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.7G      1.497      2.104      1.616        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:17<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.228      0.244      0.112     0.0505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      1.436      2.012      1.574         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.329      0.305      0.209      0.101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G       1.36      1.924      1.522         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.438      0.282      0.274      0.119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G      1.317      1.786      1.485         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.49      0.442      0.382      0.158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G      1.285      1.735      1.466         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.548      0.378      0.437      0.175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G      1.247      1.632      1.432         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.555      0.451      0.444      0.203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G      1.221      1.595      1.413         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.729       0.44      0.506      0.241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G      1.198      1.523      1.398         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.646      0.469      0.521      0.242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G      1.143      1.455      1.367         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.625      0.428      0.478      0.221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G       1.22      1.457      1.434         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:20<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.678      0.529      0.558       0.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G        1.2       1.43      1.425         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.735      0.544      0.604      0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G      1.169       1.38      1.404         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.613      0.546      0.505      0.247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G      1.151      1.306      1.379         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.753      0.583      0.666      0.338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G      1.114      1.245      1.354         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.711      0.614      0.656      0.308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G      1.096      1.189      1.338         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.791      0.619      0.685      0.371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G      1.062      1.116      1.321         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.768       0.63       0.65      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G       1.04      1.077      1.294         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.817      0.652       0.74      0.387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G      1.003       1.02      1.272         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.852      0.617      0.723      0.372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G     0.9775     0.9608      1.254         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.889       0.62       0.74      0.405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.473 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.886       0.62       0.74      0.405\n",
            "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_44_lr_0003_optimizer_Adam_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 45/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'Adam', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 28.8Â±16.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.3Â±2.1 ms, read: 23.4Â±18.1 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.16G      1.511       2.22      1.645         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:18<00:00,  4.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.211      0.103     0.0673     0.0288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20       5.7G      1.504      2.228      1.646         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:14<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.359      0.238      0.164     0.0711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      5.71G      1.454      2.082      1.595         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.268      0.263      0.162     0.0698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      5.87G      1.387       1.99      1.558        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.491      0.366      0.363       0.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.24G      1.332      1.912      1.524         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.423      0.378      0.332      0.149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.78G      1.295      1.828      1.483         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.507       0.43      0.442      0.197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.78G      1.256      1.733      1.459         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.716      0.437      0.471      0.198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.78G      1.237      1.661      1.444         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.688      0.508      0.547       0.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.78G      1.205      1.608      1.424         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.712      0.496      0.517      0.261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.78G       1.18      1.584      1.407        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.644      0.451      0.494      0.236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.78G      1.232      1.551      1.461         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.732      0.488      0.576      0.285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.78G      1.222      1.504       1.46         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.788      0.476      0.566       0.27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.78G      1.192      1.457      1.443         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.769      0.555      0.611       0.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.78G      1.163       1.37      1.407         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.774       0.57      0.641      0.332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.78G      1.129      1.315      1.391         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.689      0.577      0.643      0.354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.78G      1.119      1.283      1.375         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.898       0.54      0.662      0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.78G      1.102      1.204      1.364         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.815      0.582      0.658      0.331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.78G      1.052      1.142      1.319         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.915      0.559      0.707      0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.78G      1.029      1.097      1.314         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.882      0.617      0.726       0.39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.78G     0.9946      1.025       1.28         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:21<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.85      0.656      0.742      0.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.461 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.85      0.656      0.742      0.416\n",
            "Speed: 0.2ms preprocess, 8.4ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_45_lr_0003_optimizer_Adam_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 46/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'RMSProp', 'batch_size': 32}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 27.6Â±15.8 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 2.0Â±3.7 ms, read: 11.0Â±11.0 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      18.2G      3.197      16.63       3.26         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   8.77e-05      0.038   0.000109   3.52e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      18.6G      3.148      3.583      2.944         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:19<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.334     0.0181    0.00011   3.41e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      18.8G      3.059      3.591      2.879         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   5.85e-05      0.012   5.98e-05   2.38e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      18.7G        nan        nan        nan         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:19<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000331     0.0683   0.000233    6.6e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      18.8G        nan        nan        nan         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:21<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000546      0.112   0.000578   0.000126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      18.8G        nan        nan        nan         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000565      0.116   0.000615   0.000129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      18.7G        nan        nan        nan         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000536       0.11   0.000564   0.000124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      18.7G        nan        nan        nan        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000556      0.114   0.000606   0.000128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      18.8G        nan        nan        nan        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000556      0.114   0.000608   0.000128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      18.7G        nan        nan        nan         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000546      0.112   0.000581   0.000125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      18.7G        nan        nan        nan         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:18<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000546      0.112    0.00061   0.000129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      18.7G        nan        nan        nan         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000536       0.11   0.000574   0.000126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      18.5G        nan        nan        nan         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000536       0.11   0.000571   0.000126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      18.5G        nan        nan        nan         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000526      0.108   0.000574   0.000124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      18.5G        nan        nan        nan         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000526      0.108   0.000579   0.000124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      18.5G        nan        nan        nan         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000526      0.108    0.00058   0.000125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      18.7G        nan        nan        nan         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000546      0.112   0.000596   0.000128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      18.5G        nan        nan        nan         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000536       0.11   0.000603   0.000128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      18.5G        nan        nan        nan         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000526      0.108   0.000564   0.000126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      18.7G        nan        nan        nan         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:17<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000536       0.11   0.000602   0.000127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.455 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000546      0.112   0.000599   0.000126\n",
            "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_46_lr_0003_optimizer_RMSProp_batch_size_32\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 47/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'RMSProp', 'batch_size': 16}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 38.0Â±19.7 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.9Â±0.4 ms, read: 15.9Â±13.9 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      9.31G      3.147      8.106      3.104         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000263     0.0589   0.000188   5.22e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      10.8G      3.014      3.523      2.821        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:15<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00164     0.0924     0.0013   0.000429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      10.8G      2.859      3.544      2.791         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:21<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   5.23e-05    0.00422   1.11e-05   4.31e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      10.8G      2.795      3.529      2.761         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:18<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      10.9G        nan        nan        nan         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:16<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      10.9G        nan        nan        nan         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:16<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      10.9G        nan        nan        nan         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      10.9G        nan        nan        nan         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      10.9G        nan        nan        nan         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      10.9G        nan        nan        nan         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      10.9G        nan        nan        nan         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:14<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      10.9G        nan        nan        nan         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      10.9G        nan        nan        nan         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      10.9G        nan        nan        nan         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      10.9G        nan        nan        nan         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      10.9G        nan        nan        nan         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      10.9G        nan        nan        nan         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      10.9G        nan        nan        nan         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      10.9G        nan        nan        nan         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      10.9G        nan        nan        nan         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.430 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286    0.00157     0.0884    0.00127   0.000415\n",
            "Speed: 0.2ms preprocess, 9.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_47_lr_0003_optimizer_RMSProp_batch_size_16\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Running combination 48/48\n",
            "Parameters: {'lr': 0.003, 'optimizer': 'RMSProp', 'batch_size': 8}\n",
            "================================================================================\n",
            "\n",
            "New https://pypi.org/project/ultralytics/8.3.143 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=RMSProp, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/PPE-detection/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,634,466 parameters, 43,634,450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 6.7Â±14.2 ms, read: 24.4Â±20.7 MB/s, size: 55.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/dataset/train/labels.cache... 2605 images, 75 backgrounds, 5 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: ignoring corrupt image/label: Label class 8 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/dataset/train/images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: ignoring corrupt image/label: Label class 9 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 42.4Â±21.8 MB/s, size: 48.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/dataset/valid/labels.cache... 114 images, 30 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.003, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      5.18G       3.04      4.613      3.177         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.667     0.0924   0.000808    0.00024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      5.72G      2.765       3.56      2.916         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:13<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000324     0.0663   0.000196   4.51e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      6.06G      2.667      3.414      2.703         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000933      0.151   0.000667   0.000165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      6.11G      2.451      3.159      2.398        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286   0.000584     0.0383   0.000317   6.91e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      6.14G      2.283      3.009      2.278         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.002      0.258    0.00384   0.000786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      6.14G      2.173      2.912       2.17         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:20<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.334     0.0141    0.00122   0.000418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      6.14G      2.095      2.837      2.106         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.671    0.00201   0.000403    0.00014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      6.14G      2.045      2.779      2.052         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0024     0.0622    0.00215   0.000582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20      6.14G      1.991      2.736      2.011         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:18<00:00,  4.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.37     0.0404    0.00893    0.00276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      6.47G      1.964      2.684      1.988        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0443     0.0704     0.0111    0.00237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      6.47G      1.999      2.767      2.071         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:17<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0031      0.299      0.013    0.00349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      6.47G      1.929      2.686      2.006         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:23<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0151      0.305     0.0254    0.00669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      6.47G      1.888      2.609      1.975         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286       0.39     0.0588     0.0303    0.00857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      6.51G      1.858      2.557      1.951         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.481      0.117     0.0464     0.0104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      6.51G      1.825      2.509      1.941         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286     0.0696      0.117     0.0373    0.00967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      6.51G      1.825      2.489      1.919         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.494     0.0738      0.063     0.0197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      6.51G      1.801      2.456      1.904         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.434      0.091     0.0497     0.0155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      6.51G      1.785      2.406      1.873         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:16<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.526      0.127      0.123      0.033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      6.51G      1.754      2.382      1.866         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:22<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.117       0.11     0.0744     0.0205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      6.51G      1.732       2.36      1.852         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [01:15<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.336      0.161      0.101     0.0331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.454 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8/weights/last.pt, 87.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8/weights/best.pt, 87.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "Model summary (fused): 112 layers, 43,611,234 parameters, 0 gradients, 164.8 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        114        286      0.531      0.127      0.125     0.0335\n",
            "Speed: 0.3ms preprocess, 10.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/PPE-detection/runs/detection-PPEv7_gs_48_lr_0003_optimizer_RMSProp_batch_size_8\u001b[0m\n",
            "Saved intermediate results to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "\n",
            "Current best model:\n",
            "Parameters: {\n",
            "  \"lr\": 0.0001,\n",
            "  \"optimizer\": \"AdamW\",\n",
            "  \"batch_size\": 32\n",
            "}\n",
            "mAP50-95: 0.6728\n",
            "mAP50: 0.922071\n",
            "Precision: 0.9606\n",
            "Recall: 0.8237\n",
            "Training time: 1735.32 seconds\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Grid search completed. Results saved to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_results_20250522_152154.csv\n",
            "Summary saved to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/gridsearch_summary_20250522_152154.txt\n",
            "Created directory: /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/plots\n",
            "Visualizations saved to /content/drive/MyDrive/PPE-detection/gridsearch/yolov8l/plots\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "    # Run grid search\n",
        "    best_params = run_gridsearch()\n",
        "\n",
        "    # Find the latest results file\n",
        "    results_dir = CFG.GRIDSEARCH_DIR\n",
        "    results_files = [f for f in os.listdir(results_dir) if f.endswith('.csv')]\n",
        "    latest_results_file = max([os.path.join(results_dir, f) for f in results_files], key=os.path.getmtime)\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(latest_results_file)\n",
        "\n",
        "    # # Ask user if they want to train with best parameters\n",
        "    # user_input = input(\"\\nDo you want to train the final model with the best parameters? (y/n): \")\n",
        "    # if user_input.lower() in ['y', 'yes']:\n",
        "    #     final_results = train_with_best_params(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r17a4WPZUuRA",
        "outputId": "2d59b7d7-de1f-46ab-a95a-f72b935273e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(f\"{'='*80}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clP6Rt1tw-61"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOY86vtix9hrWVKwREy8E6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}